{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from voting_games.werewolf_env_v0 import plurality_env, Roles, Phase\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plurality Voting\n",
    "\n",
    "Blurb on plurality voting goes here...\n",
    "\n",
    "We want to see how an static agents vs static wolves fare, before training our PPO agents to hopefully learn to do better"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training Baselines\n",
    "\n",
    "To properly asses our agents, we need baselines. For this purpose we have totally random villagers and semi-random villagers that will only vote for agents that are currently alive.\n",
    "\n",
    "As for wolves, we have the following behaviors:\n",
    "- wolves that coordinate and each target one villager\n",
    "- random wolves that do whatever\n",
    "- revenge wolves that coordinate and target a random villager that targetted a wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 players, with 2 wolves\n",
      "\n",
      "Wolf Strategy         Semi-Smart Villager    Totally Random Villager\n",
      "------------------  ---------------------  -------------------------\n",
      "Coordinated Wolves                  0.126                      0.045\n",
      "Random Wolves                       0.694                      0.597\n",
      "\n",
      "\n",
      "15 players, with 3 wolves\n",
      "\n",
      "Wolf Strategy         Semi-Smart Villager    Totally Random Villager\n",
      "------------------  ---------------------  -------------------------\n",
      "Coordinated Wolves                  0.033                      0.002\n",
      "Random Wolves                       0.741                      0.58\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def revenge_coordinated_wolf(env, actions = None):\n",
    "#     villagers_remaining = set(env.world_state[\"villagers\"]) & set(env.world_state['alive'])\n",
    "#     wolves_remaining = set(env.world_state[\"werewolves\"]) & set(env.world_state['alive'])\n",
    "\n",
    "#     # who tried to vote out a wolf last time?\n",
    "    \n",
    "#     target = random.choice(list(villagers_remaining))\n",
    "#     # pick \n",
    "#     for wolf in wolves_remaining:\n",
    "#         actions[wolf] = [0] * len(env.possible_agents)\n",
    "#         actions[wolf][int(target.split(\"_\")[-1])] = -1\n",
    "#         for curr_wolf in wolves_remaining:\n",
    "#             actions[wolf][int(curr_wolf.split(\"_\")[-1])] = 1\n",
    "#     # for wolf in env.werewolves_remaining:\n",
    "\n",
    "def random_single_target_villager(env, agent):\n",
    "    targets = set(env.world_state[\"alive\"]) - set([agent])\n",
    "    return int(random.choice(list(targets)).split(\"_\")[-1])\n",
    "\n",
    "# random_coordinated_wolf(env)\n",
    "def random_agent_action(env, agent, action=None):\n",
    "   return env.action_space(agent).sample()\n",
    "\n",
    "def random_coordinated_single_wolf(env, agent, action=None):\n",
    "    villagers_remaining = set(env.world_state[\"villagers\"]) & set(env.world_state['alive'])\n",
    "    return action if action != None else int(random.choice(list(villagers_remaining)).split(\"_\")[-1])\n",
    "\n",
    "\n",
    "def play_static_wolf_game(env, wolf_policy, villager_agent, num_times=100):\n",
    "\n",
    "    villager_wins = 0\n",
    "    game_replays = []\n",
    "    for _ in range(num_times):\n",
    "        observations, rewards, terminations, truncations, infos = env.reset()\n",
    "        \n",
    "        wolf_action = None\n",
    "        while env.agents:\n",
    "            actions = {}\n",
    "\n",
    "            villagers = set(env.agents) & set(env.world_state[\"villagers\"])\n",
    "            wolves = set(env.agents) & set(env.world_state[\"werewolves\"])\n",
    "\n",
    "            # villager steps\n",
    "            for villager in villagers:\n",
    "                actions[villager] = villager_agent(env, villager)\n",
    "\n",
    "\n",
    "            # wolf steps\n",
    "            phase = env.world_state['phase']\n",
    "            for wolf in wolves:\n",
    "                wolf_action = wolf_policy(env, wolf, action=wolf_action)\n",
    "                actions[wolf] = wolf_action\n",
    "        \n",
    "            observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "\n",
    "\n",
    "            if env.world_state['phase'] == Phase.NIGHT:\n",
    "                wolf_action = None\n",
    "            \n",
    "            if env.world_state['phase'] == Phase.ACCUSATION and phase == Phase.NIGHT:\n",
    "                wolf_action = None\n",
    "\n",
    "        winner = env.world_state['winners']\n",
    "        if winner == Roles.VILLAGER:\n",
    "            villager_wins += 1\n",
    "\n",
    "        game_replays.append(copy.deepcopy(env.history))\n",
    "\n",
    "    return villager_wins, game_replays\n",
    "\n",
    "env = plurality_env(num_agents=10, werewolves=2, num_accusations=1)\n",
    "env.reset()\n",
    "print(f'10 players, with 2 wolves\\n')\n",
    "\n",
    "\n",
    "coordinated_wolves = []\n",
    "coordinated_wolves.append(play_static_wolf_game(env, random_coordinated_single_wolf, random_single_target_villager, num_times=1000)[0]/1000.0)\n",
    "coordinated_wolves.append(play_static_wolf_game(env, random_coordinated_single_wolf, random_agent_action, num_times=1000)[0]/1000.0)\n",
    "\n",
    "random_wolves = []\n",
    "random_wolves.append(play_static_wolf_game(env, random_agent_action, random_single_target_villager, num_times=1000)[0]/1000.0)\n",
    "random_wolves.append(play_static_wolf_game(env, random_agent_action, random_agent_action, num_times=1000)[0]/1000.0)\n",
    "\n",
    "print(tabulate([['Coordinated Wolves', *coordinated_wolves], ['Random Wolves', *random_wolves]], \n",
    "               headers=[\"Wolf Strategy\", \"Semi-Smart Villager\", \"Totally Random Villager\"]))\n",
    "\n",
    "print(\"\\n\")\n",
    "env = plurality_env(num_agents=15, werewolves=3, num_accusations=1)\n",
    "env.reset()\n",
    "print(f'15 players, with 3 wolves\\n')\n",
    "\n",
    "coordinated_wolves = []\n",
    "coordinated_wolves.append(play_static_wolf_game(env, random_coordinated_single_wolf, random_single_target_villager, num_times=1000)[0]/1000.0)\n",
    "coordinated_wolves.append(play_static_wolf_game(env, random_coordinated_single_wolf, random_agent_action, num_times=1000)[0]/1000.0)\n",
    "\n",
    "random_wolves = []\n",
    "random_wolves.append(play_static_wolf_game(env, random_agent_action, random_single_target_villager, num_times=1000)[0]/1000.0)\n",
    "random_wolves.append(play_static_wolf_game(env, random_agent_action, random_agent_action, num_times=1000)[0]/1000.0)\n",
    "\n",
    "print(tabulate([['Coordinated Wolves', *coordinated_wolves], ['Random Wolves', *random_wolves]], \n",
    "               headers=[\"Wolf Strategy\", \"Semi-Smart Villager\", \"Totally Random Villager\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets see what trained agents against coordinated wolves looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
