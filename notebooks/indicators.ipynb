{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from voting_games.werewolf_env_v0 import plurality_env, pare, Phase, Roles\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from notebooks.learning_agents.models import ActorCriticAgent\n",
    "from notebooks.learning_agents.utils import play_recurrent_game\n",
    "from notebooks.learning_agents.static_agents import random_approval_wolf, random_plurality_wolf\n",
    "import notebooks.learning_agents.stats as indicators \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gameplay Indicators\n",
    "\n",
    "Now that we have trained agents, we want to see what kind of indicators possibly match up with learned voting behaviors, and how explainable they are. We do this for both plurality and approval voting mechanisms. \n",
    "\n",
    "\n",
    "```{note}\n",
    "The way the environment stores history is slightly different than observations. Whereas the latter stores the prior votes, env.history steps have the votes and the outcomes that occured at that particular day/phase/round.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load up data\n",
    "\n",
    "We are going to use replays from our trained agents to investigate these various markers. 1000 games of each voting type will be used.\n",
    "\n",
    "### Plurality Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained villagers won 486 games\n",
      "Untrained villagers won 47 games\n"
     ]
    }
   ],
   "source": [
    "env = plurality_env(num_agents=10, werewolves=2, num_accusations=2)\n",
    "observations, _, _, _, _ = env.reset()\n",
    "\n",
    "obs_size= env.convert_obs(observations['player_0']['observation']).shape[-1]\n",
    "\n",
    "untrained_plurality_agent = ActorCriticAgent({\"rec_hidden_size\": 128, \n",
    "                                        \"rec_layers\": 1,\n",
    "                                        \"joint_mlp_size\": 128,\n",
    "                                        \"split_mlp_size\": 128,\n",
    "                                        \"num_votes\": 1,\n",
    "                                        \"approval_states\": 10},\n",
    "                                        num_players=10,\n",
    "                                        obs_size=obs_size)\n",
    "\n",
    "trained_plurality_agent = ActorCriticAgent({\"rec_hidden_size\": 128,\n",
    "                                        \"rec_layers\": 1, \n",
    "                                        \"joint_mlp_size\": 128,\n",
    "                                        \"split_mlp_size\": 128,\n",
    "                                        \"num_votes\": 1,\n",
    "                                        \"approval_states\": 10},\n",
    "                                        num_players=10,\n",
    "                                        obs_size=obs_size)\n",
    "trained_plurality_agent.load_state_dict(torch.load(\"stored_agents/lstm_first_no_one_hot_128_128/plurality_agent_10_score_46\"))\n",
    "\n",
    "# random_agent = None\n",
    "\n",
    "trained_plurality_wins, trained_plurality_replays = play_recurrent_game(env, random_plurality_wolf, trained_plurality_agent, num_times=1000, hidden_state_size=128, voting_type=\"plurality\")\n",
    "untrained_plurality_wins, untrained_plurality_replays = play_recurrent_game(env, random_plurality_wolf, untrained_plurality_agent, num_times=1000, hidden_state_size=128, voting_type=\"plurality\")\n",
    "# random_wins, random_replays = play_recurrent_game_w_replays(env, random_coordinated_single_wolf, random_agent, num_times=1000, hidden_state_size=128, voting_type=\"plurality\")\n",
    "\n",
    "trained_plurality_villager_wins = [r for r in trained_plurality_replays if r[-1][\"winners\"] == Roles.VILLAGER]\n",
    "print(f'Trained villagers won {trained_plurality_wins} games')\n",
    "untrained_plurality_villager_wins = [r for r in untrained_plurality_replays if r[-1][\"winners\"] == Roles.VILLAGER]\n",
    "print(f'Untrained villagers won {untrained_plurality_wins} games')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approval Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained villagers won 507 games\n",
      "Untrained villagers won 62 games\n"
     ]
    }
   ],
   "source": [
    "env = pare(num_agents=10, werewolves=2, num_accusations=2)\n",
    "observations, _, _, _, _ = env.reset()\n",
    "\n",
    "obs_size= env.convert_obs(observations['player_0']['observation']).shape[-1]\n",
    "observations['player_0']['observation']\n",
    "\n",
    "untrained_approval_agent = ActorCriticAgent({\"rec_hidden_size\": 256, \n",
    "                                        \"rec_layers\": 1,\n",
    "                                        \"joint_mlp_size\": 128,\n",
    "                                        \"split_mlp_size\": 128,\n",
    "                                        \"num_votes\": 10,\n",
    "                                        \"approval_states\": 3},\n",
    "                                        num_players=10,\n",
    "                                        obs_size=obs_size)\n",
    "\n",
    "trained_approval_agent = ActorCriticAgent({\"rec_hidden_size\": 256,\n",
    "                                        \"rec_layers\": 1, \n",
    "                                        \"joint_mlp_size\": 128,\n",
    "                                        \"split_mlp_size\": 128,\n",
    "                                        \"num_votes\": 10,\n",
    "                                        \"approval_states\": 3},\n",
    "                                        num_players=10,\n",
    "                                        obs_size=obs_size)\n",
    "trained_approval_agent.load_state_dict(torch.load(\"stored_agents/lstm_first_no_one_hot_256_128/approval_agent_10_score_49\"))\n",
    "\n",
    "# random_agent = None\n",
    "\n",
    "trained_approval_wins, trained_approval_replays = play_recurrent_game(env, random_approval_wolf, trained_approval_agent, num_times=1000, hidden_state_size=256, voting_type=\"approval\")\n",
    "untrained_approval_wins, untrained_approval_replays = play_recurrent_game(env, random_approval_wolf, untrained_approval_agent, num_times=1000, hidden_state_size=256, voting_type=\"approval\")\n",
    "# random_wins, random_replays = play_recurrent_game_w_replays(env, random_coordinated_single_wolf, random_agent, num_times=1000, hidden_state_size=128, voting_type=\"plurality\")\n",
    "\n",
    "trained_approval_villager_wins = [r for r in trained_approval_replays if r[-1][\"winners\"] == Roles.VILLAGER]\n",
    "print(f'Trained villagers won {trained_approval_wins} games')\n",
    "untrained_approval_villager_wins = [r for r in untrained_approval_replays if r[-1][\"winners\"] == Roles.VILLAGER]\n",
    "print(f'Untrained villagers won {untrained_approval_wins} games')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days elapsed before a villager win\n",
    "\n",
    "Looking at the average amount of days elapsed before villagers win is a metric that highlights positive learning and collaboration trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average amount of days until a win is achieved by villagers in plurality games\n",
      "\t Trained villagers : 2.987368\n",
      "\t Untrained villagers : 3.076923\n",
      "\n",
      "\n",
      "Average amount of days until a win is achieved by villagers in approval games\n",
      "\t Trained villagers : 2.970833\n",
      "\t Untrained villagers : 3.376471\n"
     ]
    }
   ],
   "source": [
    "print(\"Average amount of days until a win is achieved by villagers in plurality games\")\n",
    "print(f'\\t Trained villagers : {np.mean([villager_win[-1][\"day\"] for villager_win in trained_plurality_villager_wins]):2f}')\n",
    "print(f'\\t Untrained villagers : {np.mean([villager_win[-1][\"day\"] for villager_win in untrained_plurality_villager_wins]):2f}')\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average amount of days until a win is achieved by villagers in approval games\")\n",
    "print(f'\\t Trained villagers : {np.mean([villager_win[-1][\"day\"] for villager_win in trained_approval_villager_wins]):2f}')\n",
    "print(f'\\t Untrained villagers : {np.mean([villager_win[-1][\"day\"] for villager_win in untrained_approval_villager_wins]):2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days between wolf executions\n",
    "\n",
    "Looking at the distance in days between wolf executions also highlights positive trends in learning and collaboration, as the lower the number, the more likely villagers were able to confidently coordinate and identify the wolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average amount of days until the next wolf was killed in plurality games for 2 wolf environments\n",
      "\tDays between wolf kills for trained agents : 1.581\n",
      "\tDays between wolf kills for untrained agents : 1.667\n",
      "\n",
      "\n",
      "Average amount of days until the next wolf was killed in approval games for 2 wolf environments\n",
      "\tDays between wolf kills for trained agents : 1.448\n",
      "\tDays between wolf kills for untrained agents : 1.659\n"
     ]
    }
   ],
   "source": [
    "print(\"Average amount of days until the next wolf was killed in plurality games for 2 wolf environments\")\n",
    "wolf_execution_days = \\\n",
    "    [indicators._when_did_wolves_get_killed(trained_villager_win) for trained_villager_win in trained_plurality_villager_wins]\n",
    "wolf_execution_duration_between = [b-a for a,b in wolf_execution_days]\n",
    "print(f'\\tDays between wolf kills for trained agents : {np.mean(wolf_execution_duration_between):.3f}')\n",
    "\n",
    "wolf_execution_days = \\\n",
    "    [indicators._when_did_wolves_get_killed(untrained_villager_win) for untrained_villager_win in untrained_plurality_villager_wins]\n",
    "wolf_execution_duration_between = [b-a for a,b in wolf_execution_days]\n",
    "print(f'\\tDays between wolf kills for untrained agents : {np.mean(wolf_execution_duration_between):.3f}')\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average amount of days until the next wolf was killed in approval games for 2 wolf environments\")\n",
    "wolf_execution_days = \\\n",
    "    [indicators._when_did_wolves_get_killed(trained_villager_win) for trained_villager_win in trained_approval_villager_wins]\n",
    "wolf_execution_duration_between = [b-a for a,b in wolf_execution_days]\n",
    "print(f'\\tDays between wolf kills for trained agents : {np.mean(wolf_execution_duration_between):.3f}')\n",
    "\n",
    "wolf_execution_days = \\\n",
    "    [indicators._when_did_wolves_get_killed(untrained_villager_win) for untrained_villager_win in untrained_approval_villager_wins]\n",
    "wolf_execution_duration_between = [b-a for a,b in wolf_execution_days]\n",
    "print(f'\\tDays between wolf kills for untrained agents : {np.mean(wolf_execution_duration_between):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targetting Indicators\n",
    "\n",
    "Picking the right indicators to try and describe targetting behavior is not straightforward, and differs between plurality and approval voting. Below are the ones currently chosen for both game types, along with a rendering of them across days and phases in a randomly selected game.\n",
    "\n",
    "#### Plurality\n",
    "        target_record[step['day']].append([unique_villager_votes,\n",
    "                                           avg_self_vote,\n",
    "                                           percent_of_villagers_targetting_wolves, \n",
    "                                           percent_of_villagers_targetting_dead_players, \n",
    "                                           percent_of_villagers_targetting_a_dead_wol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wolves : ['player_0', 'player_3']\n",
      "\n",
      "Day : 1 | Phase : 0 | Round : 0\n",
      "Villager votes : [9, 9, 9, 3, 9, 9, 5, 2]\n",
      "\t | - Ratio of unique players targetted : 0.5\n",
      "\t | - 0.125 of the votes targetting wolves\n",
      "\t | - 0.125 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 1 | Phase : 0 | Round : 1\n",
      "Villager votes : [3, 9, 9, 7, 7, 8, 6, 7]\n",
      "\t | - Ratio of unique players targetted : 0.625\n",
      "\t | - 0.125 of the votes targetting wolves\n",
      "\t | - 0.125 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 1 | Phase : 1 | Round : 0\n",
      "Villager votes : [2, 8, 9, 8, 9, 0, 3, 8]\n",
      "\t | - Ratio of unique players targetted : 0.625\n",
      "\t | - 0.250 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 2 | Phase : 0 | Round : 0\n",
      "Villager votes : [9, 6, 9, 8, 3, 8]\n",
      "\t | - Ratio of unique players targetted : 0.6666666666666666\n",
      "\t | - 0.167 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.333 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 2 | Phase : 0 | Round : 1\n",
      "Villager votes : [8, 3, 3, 8, 3, 8]\n",
      "\t | - Ratio of unique players targetted : 0.3333333333333333\n",
      "\t | - 0.500 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 2 | Phase : 1 | Round : 0\n",
      "Villager votes : [7, 3, 0, 0, 0, 0]\n",
      "\t | - Ratio of unique players targetted : 0.5\n",
      "\t | - 0.833 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 3 | Phase : 0 | Round : 0\n",
      "Villager votes : [3, 8, 8, 0, 9]\n",
      "\t | - Ratio of unique players targetted : 0.8\n",
      "\t | - 0.400 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.400 share of villager votes targetting dead players\n",
      "\t | - 0.200 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 3 | Phase : 0 | Round : 1\n",
      "Villager votes : [8, 7, 3, 3, 8]\n",
      "\t | - Ratio of unique players targetted : 0.6\n",
      "\t | - 0.400 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 3 | Phase : 1 | Round : 0\n",
      "Villager votes : [3, 3, 6, 3, 6]\n",
      "\t | - Ratio of unique players targetted : 0.4\n",
      "\t | - 0.600 of the votes targetting wolves\n",
      "\t | - 0.2 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n"
     ]
    }
   ],
   "source": [
    "record = indicators._plurality_target_indicators(trained_plurality_villager_wins[0], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_records = indicators._game_avg_records(trained_plurality_villager_wins, indicators._plurality_target_indicators)\n",
    "avg_records_untrained = indicators._game_avg_records(untrained_plurality_villager_wins, indicators._plurality_target_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.5627572  0.04603909 0.21656379 0.         0.        ]\n",
      "  [0.53986626 0.04063786 0.37757202 0.         0.        ]\n",
      "  [0.47299383 0.03009259 0.54346708 0.         0.        ]]\n",
      "\n",
      " [[0.5930825  0.04580639 0.31334509 0.22050754 0.09082892]\n",
      "  [0.53434254 0.04805996 0.39506173 0.07975701 0.02704292]\n",
      "  [0.49848129 0.04600235 0.44816774 0.05070547 0.01646091]]\n",
      "\n",
      " [[0.64127726 0.04376947 0.28504673 0.41417445 0.07102804]\n",
      "  [0.61464174 0.05264798 0.39813084 0.23084112 0.03738318]\n",
      "  [0.57866044 0.05249221 0.48364486 0.155919   0.02367601]]\n",
      "\n",
      " [[0.73763441 0.02580645 0.31397849 0.61935484 0.07311828]\n",
      "  [0.75913978 0.03870968 0.4688172  0.42150538 0.0516129 ]\n",
      "  [0.65806452 0.01290323 0.65806452 0.28387097 0.02365591]]]\n",
      "[[0.5627572  0.53986626 0.47299383]\n",
      " [0.5930825  0.53434254 0.49848129]\n",
      " [0.64127726 0.61464174 0.57866044]\n",
      " [0.73763441 0.75913978 0.65806452]]\n",
      "[0.5627572  0.53986626 0.47299383]\n",
      "[0.5627572  0.5930825  0.64127726 0.73763441]\n"
     ]
    }
   ],
   "source": [
    "stacked = np.stack(list(avg_records.values()))\n",
    "stacked_untracked = np.stack(list(avg_records_untrained.values()))\n",
    "\n",
    "print(stacked[:,:,:])\n",
    "\n",
    "print(stacked[:,:,0])\n",
    "\n",
    "print(stacked[:,:,0][0])\n",
    "print(stacked[:,:,0][:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approval_target_indicators(game, verbose=False):\n",
    "    wolves = game[0]['werewolves']\n",
    "    villagers = game[0]['villagers']\n",
    "\n",
    "    # this will be an object of lists with each list containing the accusation and voting stats for the day\n",
    "    target_record = {}\n",
    "    \n",
    "    vote_rounds = []\n",
    "    for i, step in enumerate(game):\n",
    "\n",
    "        if step['phase'] == Phase.NIGHT or i == 0:\n",
    "            continue\n",
    "        if step[\"phase\"] == Phase.VOTING:\n",
    "            vote_rounds.append(step)\n",
    "        if step['day'] not in target_record.keys():\n",
    "            target_record[step['day']] = []\n",
    "\n",
    "        villager_votes = [vote for player, vote in step['votes'].items() if player not in wolves]\n",
    "        all_votes = list(step['votes'].values())\n",
    "\n",
    "        villager_targets = [np.where(np.array(villager_vote) == -1)[0] for villager_vote in villager_votes]\n",
    "        villager_likes = [np.where(np.array(villager_vote) == 1)[0] for villager_vote in villager_votes]\n",
    "        villager_neutrals = [np.where(np.array(villager_vote) == 0)[0] for villager_vote in villager_votes]\n",
    "\n",
    "        v_target_counter = Counter(np.concatenate(villager_targets))\n",
    "        v_like_counter = Counter(np.concatenate(villager_likes))\n",
    "        v_neutral_counter = Counter(np.concatenate(villager_neutrals))\n",
    "\n",
    "        ## AVERAGE UNIQUE TARGETS, LIKES, NEUTRALS ## \n",
    "        v_avg_target_count = np.mean([len(targets) for targets in villager_targets])\n",
    "        v_avg_like_count = np.mean([len(targets) for targets in villager_likes])\n",
    "        v_avg_neutral_count = np.mean([len(targets) for targets in villager_neutrals])\n",
    "\n",
    "        # do villagers target themselves and or like themselves\n",
    "        avg_vself_target = sum([1 for k,v in step['votes'].items() if v[int(k.split(\"_\")[-1])] == -1 and k not in wolves]) / float(len(villager_votes))\n",
    "        avg_vself_like = sum([1 for k,v in step['votes'].items() if v[int(k.split(\"_\")[-1])] == 1 and k not in wolves]) / float(len(villager_votes))\n",
    "\n",
    "        most_common_n_targets = int(len(v_target_counter)*0.3)\n",
    "        most_common_n_likes = int(len(v_like_counter)*0.3)\n",
    "\n",
    "        wolves_in_most_common_targets =\\\n",
    "            [int(wolf.split(\"_\")[-1]) for wolf in wolves if int(wolf.split(\"_\")[-1]) in [idx for idx, _ in v_target_counter.most_common(max(1,most_common_n_targets))]]\n",
    "\n",
    "        wolves_in_most_common_likes =\\\n",
    "            [int(wolf.split(\"_\")[-1]) for wolf in wolves if int(wolf.split(\"_\")[-1]) in [idx for idx, _ in v_like_counter.most_common(max(1,most_common_n_likes))]]\n",
    "\n",
    "        if step[\"phase\"] == Phase.VOTING:\n",
    "            if len(vote_rounds) == 1:\n",
    "                dead_players = []\n",
    "                dead_wolves = []\n",
    "                dead_villagers = []\n",
    "            else:\n",
    "                dead_players = list((set(step['executed']) & set(vote_rounds[-2]['executed'])) | set(step['killed']))\n",
    "                dead_wolves = list(set(wolves) & set(dead_players))\n",
    "                dead_villagers = list(set(villagers) & set(dead_players))\n",
    "        else:\n",
    "            dead_players = list(set(step['executed']) | set(step['killed']))\n",
    "            dead_wolves = list(set(wolves) & set(dead_players))\n",
    "            dead_villagers = list(set(villagers) & set(dead_players))\n",
    "        \n",
    "        # do the most liked individuals also get the least amount of votes?\n",
    "        total_target_votes = sum(v_target_counter.values())\n",
    "        total_like_votes = sum(v_like_counter.values())\n",
    "\n",
    "        # target percentages\n",
    "        percent_of_vtargets_toward_dead_players = sum([v_target_counter[int(dead_player.split(\"_\")[-1])] for dead_player in dead_players]) / float(total_target_votes)\n",
    "        percent_of_vtargets_toward_wolves = sum([v_target_counter[int(wolf.split(\"_\")[-1])] for wolf in wolves]) / float(total_target_votes)\n",
    "        percent_of_vtargets_toward_dead_wolves = sum([v_target_counter[int(dead_wolf.split(\"_\")[-1])] for dead_wolf in dead_wolves]) / float(total_target_votes)\n",
    "        percent_of_vtargets_toward_alive_wolves = sum([v_target_counter[int(wolf.split(\"_\")[-1])] for wolf in wolves if wolf not in dead_wolves]) / float(total_target_votes)\n",
    "\n",
    "        # how many likes are for other trusted villagers?\n",
    "        percentage_of_vlikes_for_alive_villagers = sum([v_like_counter[int(villager.split(\"_\")[-1])] for villager in villagers if villager not in dead_villagers]) / float(total_like_votes)\n",
    "        percentage_of_vlikes_for_dead_villagers = sum([v_like_counter[int(dead_villager.split(\"_\")[-1])] for dead_villager in dead_villagers]) / float(total_like_votes)\n",
    "\n",
    "        percentage_of_vlikes_for_dead_wolves = sum([v_like_counter[int(dead_wolf.split(\"_\")[-1])] for dead_wolf in dead_wolves]) / float(total_like_votes)\n",
    "        percentage_of_vlikes_for_alive_wolves = sum([v_like_counter[int(wolf.split(\"_\")[-1])] for wolf in wolves if wolf not in dead_wolves]) / float(total_like_votes)\n",
    "\n",
    "\n",
    "        # TODO: DO I repeat the above for numbers in the top n votes?\n",
    "        target_record[step['day']].append([v_avg_target_count,\n",
    "                                           v_avg_like_count,\n",
    "                                           v_avg_neutral_count,\n",
    "                                           avg_vself_target,\n",
    "                                           avg_vself_like,\n",
    "                                           most_common_n_targets,\n",
    "                                           len(wolves_in_most_common_targets),\n",
    "                                           most_common_n_likes,\n",
    "                                           len(wolves_in_most_common_likes),\n",
    "                                           percent_of_vtargets_toward_dead_players,\n",
    "                                           percent_of_vtargets_toward_wolves,\n",
    "                                           percent_of_vtargets_toward_dead_wolves,\n",
    "                                           percent_of_vtargets_toward_alive_wolves,\n",
    "                                           percentage_of_vlikes_for_alive_villagers,\n",
    "                                           percentage_of_vlikes_for_dead_villagers,\n",
    "                                           percentage_of_vlikes_for_dead_wolves,\n",
    "                                           percentage_of_vlikes_for_alive_wolves,\n",
    "                                           ])\n",
    "        \n",
    "\n",
    "        if verbose:\n",
    "            phase_name = \"Voting Phase\" if step['phase'] == Phase.VOTING else \"Accusation Phase\"\n",
    "            print(f'Day : {step[\"day\"]} | Phase : {step[\"phase\"]} - {phase_name} | Round : {step[\"round\"]}')\n",
    "            print(f'\\t | - avg targetted {v_avg_target_count:.2f}, liked {v_avg_like_count:.2f}, neutral {v_avg_neutral_count:.2f}, with {avg_vself_target:.2f} share of villagers targetting themselves, and {avg_vself_like:.2f} liking themselves')\n",
    "            print(f'\\t | -{len(wolves_in_most_common_targets)} wolves targetted in top {most_common_n_targets} votes')\n",
    "            print(f'\\t | -{len(wolves_in_most_common_likes)} wolves liked in top {most_common_n_likes} likes')\n",
    "            print(f'\\t | - % of votes towards dead players ({percent_of_vtargets_toward_dead_players:.2f}), towards dead wolves ({percent_of_vtargets_toward_dead_wolves:.2f}), towards wolves ({percent_of_vtargets_toward_wolves:.2f}), towards living wolves ({percent_of_vtargets_toward_alive_wolves:.2f})')\n",
    "            print(f'\\t | - % of likes towards dead wolves ({percentage_of_vlikes_for_dead_wolves:.2f}), towards alive wolves ({percentage_of_vlikes_for_alive_wolves:.2f})')\n",
    "            print(f'\\t | - % of likes towards dead villagers ({percentage_of_vlikes_for_dead_villagers:.2f}), towards alive villagers ({percentage_of_vlikes_for_alive_villagers:.2f})')\n",
    "            print(\"\\n\")\n",
    "\n",
    "    return target_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day : 1 | Phase : 0 - Accusation Phase | Round : 0\n",
      "\t | - avg targetted 4.00, liked 3.00, neutral 3.00, with 0.38 share of villagers targetting themselves, and 0.25 liking themselves\n",
      "\t | -0 wolves targetted in top 3 votes\n",
      "\t | -2 wolves liked in top 2 likes\n",
      "\t | - % of votes towards dead players (0.00), towards dead wolves (0.00), towards wolves (0.06), towards living wolves (0.06)\n",
      "\t | - % of likes towards dead wolves (0.00), towards alive wolves (0.38)\n",
      "\t | - % of likes towards dead villagers (0.00), towards alive villagers (0.62)\n",
      "\n",
      "\n",
      "Day : 1 | Phase : 0 - Accusation Phase | Round : 1\n",
      "\t | - avg targetted 2.88, liked 3.88, neutral 3.25, with 0.38 share of villagers targetting themselves, and 0.50 liking themselves\n",
      "\t | -0 wolves targetted in top 3 votes\n",
      "\t | -2 wolves liked in top 3 likes\n",
      "\t | - % of votes towards dead players (0.00), towards dead wolves (0.00), towards wolves (0.13), towards living wolves (0.13)\n",
      "\t | - % of likes towards dead wolves (0.00), towards alive wolves (0.35)\n",
      "\t | - % of likes towards dead villagers (0.00), towards alive villagers (0.65)\n",
      "\n",
      "\n",
      "Day : 1 | Phase : 1 - Voting Phase | Round : 0\n",
      "\t | - avg targetted 3.50, liked 2.88, neutral 3.62, with 0.12 share of villagers targetting themselves, and 0.62 liking themselves\n",
      "\t | -1 wolves targetted in top 2 votes\n",
      "\t | -1 wolves liked in top 2 likes\n",
      "\t | - % of votes towards dead players (0.00), towards dead wolves (0.00), towards wolves (0.39), towards living wolves (0.39)\n",
      "\t | - % of likes towards dead wolves (0.00), towards alive wolves (0.22)\n",
      "\t | - % of likes towards dead villagers (0.00), towards alive villagers (0.78)\n",
      "\n",
      "\n",
      "Day : 2 | Phase : 0 - Accusation Phase | Round : 0\n",
      "\t | - avg targetted 4.14, liked 3.29, neutral 2.57, with 0.57 share of villagers targetting themselves, and 0.29 liking themselves\n",
      "\t | -1 wolves targetted in top 3 votes\n",
      "\t | -1 wolves liked in top 3 likes\n",
      "\t | - % of votes towards dead players (0.21), towards dead wolves (0.14), towards wolves (0.17), towards living wolves (0.03)\n",
      "\t | - % of likes towards dead wolves (0.04), towards alive wolves (0.22)\n",
      "\t | - % of likes towards dead villagers (0.17), towards alive villagers (0.57)\n",
      "\n",
      "\n",
      "Day : 2 | Phase : 0 - Accusation Phase | Round : 1\n",
      "\t | - avg targetted 3.57, liked 3.57, neutral 2.86, with 0.14 share of villagers targetting themselves, and 0.43 liking themselves\n",
      "\t | -1 wolves targetted in top 3 votes\n",
      "\t | -1 wolves liked in top 2 likes\n",
      "\t | - % of votes towards dead players (0.20), towards dead wolves (0.12), towards wolves (0.16), towards living wolves (0.04)\n",
      "\t | - % of likes towards dead wolves (0.08), towards alive wolves (0.20)\n",
      "\t | - % of likes towards dead villagers (0.12), towards alive villagers (0.60)\n",
      "\n",
      "\n",
      "Day : 2 | Phase : 1 - Voting Phase | Round : 0\n",
      "\t | - avg targetted 3.14, liked 4.14, neutral 2.71, with 0.29 share of villagers targetting themselves, and 0.43 liking themselves\n",
      "\t | -1 wolves targetted in top 2 votes\n",
      "\t | -1 wolves liked in top 3 likes\n",
      "\t | - % of votes towards dead players (0.18), towards dead wolves (0.09), towards wolves (0.32), towards living wolves (0.23)\n",
      "\t | - % of likes towards dead wolves (0.14), towards alive wolves (0.07)\n",
      "\t | - % of likes towards dead villagers (0.10), towards alive villagers (0.69)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = approval_target_indicators(trained_approval_villager_wins[0], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[3.43932292, 3.28229167, 3.27838542, 0.35833333, 0.31536458,\n",
       "         2.65208333, 0.47916667, 2.58958333, 0.59583333, 0.        ,\n",
       "         0.191969  , 0.        , 0.191969  , 0.79175278, 0.        ,\n",
       "         0.        , 0.20824722],\n",
       "        [3.31640625, 3.28385417, 3.39973958, 0.33489583, 0.31276042,\n",
       "         2.58958333, 0.57708333, 2.62291667, 0.58541667, 0.        ,\n",
       "         0.20404595, 0.        , 0.20404595, 0.79348917, 0.        ,\n",
       "         0.        , 0.20651083],\n",
       "        [3.23020833, 3.39375   , 3.37604167, 0.30052083, 0.34401042,\n",
       "         2.48541667, 1.05416667, 2.57708333, 0.31666667, 0.        ,\n",
       "         0.29600124, 0.        , 0.29600124, 0.83735535, 0.        ,\n",
       "         0.        , 0.16264465]]),\n",
       " 2: array([[3.46180556, 3.21016865, 3.32802579, 0.35744048, 0.30897817,\n",
       "         2.475     , 0.48333333, 2.39583333, 0.55208333, 0.2074227 ,\n",
       "         0.19147725, 0.05698298, 0.13449426, 0.64806072, 0.13840442,\n",
       "         0.05468132, 0.15885354],\n",
       "        [3.35887897, 3.26502976, 3.37609127, 0.34806548, 0.31478175,\n",
       "         2.47083333, 0.54166667, 2.4       , 0.49375   , 0.1998454 ,\n",
       "         0.20789775, 0.0540031 , 0.15389465, 0.65836963, 0.13727505,\n",
       "         0.05604479, 0.14831052],\n",
       "        [3.16284722, 3.4078869 , 3.42926587, 0.26974206, 0.35257937,\n",
       "         2.22291667, 1.05208333, 2.38125   , 0.3       , 0.17722629,\n",
       "         0.31915906, 0.05211071, 0.26704835, 0.69056935, 0.15653554,\n",
       "         0.05790268, 0.09499243]]),\n",
       " 3: array([[3.38492537, 3.21253731, 3.40253731, 0.34641791, 0.32477612,\n",
       "         2.1761194 , 0.44179104, 2.09552239, 0.37313433, 0.39996276,\n",
       "         0.19586388, 0.08848421, 0.10737968, 0.48822231, 0.31420418,\n",
       "         0.08350005, 0.11407346],\n",
       "        [3.40373134, 3.2619403 , 3.33432836, 0.34985075, 0.29910448,\n",
       "         2.22089552, 0.50746269, 2.15820896, 0.4358209 , 0.39521575,\n",
       "         0.21491857, 0.08596019, 0.12895838, 0.48706689, 0.31254943,\n",
       "         0.09014683, 0.11023684],\n",
       "        [3.24119403, 3.29253731, 3.46626866, 0.2858209 , 0.35343284,\n",
       "         2.0238806 , 0.94626866, 2.12835821, 0.25074627, 0.35555057,\n",
       "         0.3098884 , 0.08353971, 0.22634869, 0.52028997, 0.33151597,\n",
       "         0.08833539, 0.05985867]]),\n",
       " 4: array([[3.42493639, 3.36386768, 3.21119593, 0.35368957, 0.33842239,\n",
       "         1.6870229 , 0.32824427, 1.70992366, 0.32824427, 0.59133122,\n",
       "         0.21576018, 0.10356479, 0.1121954 , 0.30716647, 0.50390244,\n",
       "         0.09940642, 0.08952467],\n",
       "        [3.49109415, 3.33333333, 3.17557252, 0.34605598, 0.30279898,\n",
       "         1.6870229 , 0.48854962, 1.67175573, 0.35114504, 0.58148216,\n",
       "         0.23602673, 0.09891614, 0.13711059, 0.29900304, 0.50890871,\n",
       "         0.10911851, 0.08296974],\n",
       "        [3.19847328, 3.38422392, 3.4173028 , 0.19847328, 0.39185751,\n",
       "         1.49618321, 0.82442748, 1.60305344, 0.16030534, 0.55385619,\n",
       "         0.33657027, 0.08819016, 0.24838011, 0.35325058, 0.51994127,\n",
       "         0.09081559, 0.03599256]])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_avg_records(trained_approval_villager_wins, approval_target_indicators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ties\n",
    "\n",
    "Ties are quite common, and could possibly be used strategically. Knowning when/if ties are occuring could possibly lead to a better understanding of agent voting patterns.\n",
    "\n",
    "What we are currenly looking for is:\n",
    "- What percentage of voting rounds are ties?\n",
    "- How often do ties in accusation rounds lead to ties in voting rounds?\n",
    "- If a wolf gets lucky and survives a tied voting round, how likey is it they get executed the next voting round?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two functions we use to achieve this:\n",
    "- `indicators._game_tie_info(game_replay, voting_type=None)` which returns if there was a tie, if and which wolf was targetted, and if a wolf died during the phase. This is done for every day and every phase in a game\n",
    "- `indicators._process_tie_info(tie_records)` takes the results above and returns:\n",
    "    - percentage of ties in accusation phases per game\n",
    "    - percentage of ties in voting phases per game\n",
    "    - likelihood of a tie in a voting phase given a tie in the prior accusation phases\n",
    "    - likelihood of a wolf getting targetting in a subsequent voting round after getting lucky and surviving a tie round where they were a target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plurality tie indicators\n",
      "\tLikelihood of ties in accusation phases : 0.29\n",
      "\tLikelihood of ties in voting phases : 0.19\n",
      "\tLikelihood of a tie in a voting phase given a tie in the prior accusation phases 0.21\n",
      "\tLikelihood of a wolf getting targetting in a subsequent voting round if they survived a tie : 0.77\n",
      "\n",
      "\n",
      "Approval tie indicators\n",
      "\tLikelihood of ties in accusation phases : 0.36\n",
      "\tLikelihood of ties in voting phases : 0.31\n",
      "\tLikelihood of a tie in a voting phase given a tie in the prior accusation phases 0.32\n",
      "\tLikelihood of a wolf getting targetting in a subsequent voting round if they survived a tie : 0.63\n"
     ]
    }
   ],
   "source": [
    "tgps = \\\n",
    "    np.nanmean(np.stack([indicators._process_tie_info(indicators._game_tie_info(trained_villager_win, voting_type=\"plurality\")) for trained_villager_win in trained_plurality_villager_wins]),axis= 0)\n",
    "tgas = \\\n",
    "    np.nanmean(np.stack([indicators._process_tie_info(indicators._game_tie_info(trained_villager_win, voting_type=\"approval\")) for trained_villager_win in trained_approval_villager_wins]), axis=0)\n",
    "\n",
    "print(\"Plurality tie indicators\")\n",
    "print(f'\\tLikelihood of ties in accusation phases : {tgps[0]:.2f}')\n",
    "print(f'\\tLikelihood of ties in voting phases : {tgps[1]:.2f}')\n",
    "print(f'\\tLikelihood of a tie in a voting phase given a tie in the prior accusation phases {tgps[2]:.2f}')\n",
    "print(f'\\tLikelihood of a wolf getting targetting in a subsequent voting round if they survived a tie : {tgps[3]:.2f}')\n",
    "print(\"\\n\")\n",
    "print(\"Approval tie indicators\")\n",
    "print(f'\\tLikelihood of ties in accusation phases : {tgas[0]:.2f}')\n",
    "print(f'\\tLikelihood of ties in voting phases : {tgas[1]:.2f}')\n",
    "print(f'\\tLikelihood of a tie in a voting phase given a tie in the prior accusation phases {tgas[2]:.2f}')\n",
    "print(f'\\tLikelihood of a wolf getting targetting in a subsequent voting round if they survived a tie : {tgas[3]:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
