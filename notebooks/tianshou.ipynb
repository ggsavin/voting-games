{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from voting_games.werewolf_env_v0 import friendly_env, Roles, Phase\n",
    "from notebooks.learning_agents.models import ActorCriticAgent\n",
    "from notebooks.learning_agents.utils import play_static_game, play_recurrent_game\n",
    "from notebooks.learning_agents.static_agents import (\n",
    "    random_plurality_villager, \n",
    "    random_coordinated_plurality_villager, \n",
    "    random_agent,\n",
    "    random_plurality_wolf,\n",
    "    revenge_plurality_wolf,\n",
    "    coordinated_revenge_plurality_wolf)\n",
    "from pettingzoo.utils.env import ParallelEnv\n",
    "from pettingzoo.utils.conversions import parallel_to_aec\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tianshou RL\n",
    "\n",
    "Tianshou is an RL platform that has seen widespread usage, and is one of the adverstised frameworks on the Farama Foundation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.10/site-packages/gym/envs/registration.py:250: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for plugin in metadata.entry_points().get(entry_point, []):\n"
     ]
    }
   ],
   "source": [
    "from tianshou.data import Collector\n",
    "from tianshou.env import DummyVectorEnv, PettingZooEnv\n",
    "from tianshou.policy import RandomPolicy, MultiAgentPolicyManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'player_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[39m=\u001b[39m parallel_to_aec(friendly_env(num_agents\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, werewolves\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m env \u001b[39m=\u001b[39m PettingZooEnv(env)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tianshou/env/pettingzoo_env.py:66\u001b[0m, in \u001b[0;36mPettingZooEnv.__init__\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mobservation_space(agent) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space\n\u001b[1;32m     55\u001b[0m            \u001b[39mfor\u001b[39;00m agent \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magents), \\\n\u001b[1;32m     56\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mObservation spaces for all agents must be identical. Perhaps \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m     57\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSuperSuit\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms pad_observations wrapper can help (useage: \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m     58\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`supersuit.aec_wrappers.pad_observations(env)`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39maction_space(agent) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\n\u001b[1;32m     61\u001b[0m            \u001b[39mfor\u001b[39;00m agent \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magents), \\\n\u001b[1;32m     62\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAction spaces for all agents must be identical. Perhaps \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m     63\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSuperSuit\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms pad_action_space wrapper can help (useage: \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m     64\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`supersuit.aec_wrappers.pad_action_space(env)`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 66\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tianshou/env/pettingzoo_env.py:71\u001b[0m, in \u001b[0;36mPettingZooEnv.reset\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mdict\u001b[39m, \u001b[39mdict\u001b[39m]:\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mreset(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 71\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mlast(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(observation, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39maction_mask\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m observation:\n\u001b[1;32m     74\u001b[0m         observation_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m     75\u001b[0m             \u001b[39m'\u001b[39m\u001b[39magent_id\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39magent_selection,\n\u001b[1;32m     76\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mobs\u001b[39m\u001b[39m'\u001b[39m: observation[\u001b[39m'\u001b[39m\u001b[39mobservation\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     77\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m             [\u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m obm \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m obm \u001b[39min\u001b[39;00m observation[\u001b[39m'\u001b[39m\u001b[39maction_mask\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m     79\u001b[0m         }\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pettingzoo/utils/env.py:190\u001b[0m, in \u001b[0;36mAECEnv.last\u001b[0;34m(self, observe)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39massert\u001b[39;00m agent\n\u001b[1;32m    184\u001b[0m observation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobserve(agent) \u001b[39mif\u001b[39;00m observe \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    186\u001b[0m     observation,\n\u001b[1;32m    187\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cumulative_rewards[agent],\n\u001b[1;32m    188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mterminations[agent],\n\u001b[1;32m    189\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtruncations[agent],\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfos[agent],\n\u001b[1;32m    191\u001b[0m )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'player_0'"
     ]
    }
   ],
   "source": [
    "env = parallel_to_aec(friendly_env(num_agents=10, werewolves=2))\n",
    "env = PettingZooEnv(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'raw_env' object has no attribute 'last'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[39m=\u001b[39m plurality_env(num_agents\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, werewolves\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m env \u001b[39m=\u001b[39m PettingZooEnv(env)\n\u001b[1;32m      4\u001b[0m \u001b[39m# each agent needs a policy\u001b[39;00m\n\u001b[1;32m      5\u001b[0m policies \u001b[39m=\u001b[39m MultiAgentPolicyManager([RandomPolicy() \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m)], env)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tianshou/env/pettingzoo_env.py:66\u001b[0m, in \u001b[0;36mPettingZooEnv.__init__\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mobservation_space(agent) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space\n\u001b[1;32m     55\u001b[0m            \u001b[39mfor\u001b[39;00m agent \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magents), \\\n\u001b[1;32m     56\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mObservation spaces for all agents must be identical. Perhaps \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m     57\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSuperSuit\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms pad_observations wrapper can help (useage: \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m     58\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`supersuit.aec_wrappers.pad_observations(env)`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39maction_space(agent) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\n\u001b[1;32m     61\u001b[0m            \u001b[39mfor\u001b[39;00m agent \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magents), \\\n\u001b[1;32m     62\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAction spaces for all agents must be identical. Perhaps \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m     63\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSuperSuit\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms pad_action_space wrapper can help (useage: \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m     64\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`supersuit.aec_wrappers.pad_action_space(env)`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 66\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tianshou/env/pettingzoo_env.py:71\u001b[0m, in \u001b[0;36mPettingZooEnv.reset\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mdict\u001b[39m, \u001b[39mdict\u001b[39m]:\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mreset(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 71\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mlast(\u001b[39mself\u001b[39m)\n\u001b[1;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(observation, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39maction_mask\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m observation:\n\u001b[1;32m     74\u001b[0m         observation_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m     75\u001b[0m             \u001b[39m'\u001b[39m\u001b[39magent_id\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39magent_selection,\n\u001b[1;32m     76\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mobs\u001b[39m\u001b[39m'\u001b[39m: observation[\u001b[39m'\u001b[39m\u001b[39mobservation\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     77\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m             [\u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m obm \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m obm \u001b[39min\u001b[39;00m observation[\u001b[39m'\u001b[39m\u001b[39maction_mask\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m     79\u001b[0m         }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'raw_env' object has no attribute 'last'"
     ]
    }
   ],
   "source": [
    "env = parallel_to_aec(friendly_env(num_agents=10, werewolves=2))\n",
    "env = PettingZooEnv(env)\n",
    "\n",
    "# each agent needs a policy\n",
    "policies = MultiAgentPolicyManager([RandomPolicy() for _ in range(10)], env)\n",
    "\n",
    "# env needs to be converted to vector format\n",
    "env = DummyVectorEnv([lambda: env])\n",
    "\n",
    "#Construct the Collector, which interfaces the policies with the vectorised environment\n",
    "collector = Collector(policies, env)\n",
    "\n",
    "result = collector.collect(n_episode=1, render=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'raw_env' object has no attribute 'agent_idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m policy \u001b[39m=\u001b[39m MultiAgentPolicyManager([RandomPolicy() \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m10\u001b[39;49m)], env)\n\u001b[1;32m      2\u001b[0m env \u001b[39m=\u001b[39m DummyVectorEnv([\u001b[39mlambda\u001b[39;00m: env])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tianshou/policy/multiagent/mapolicy.py:32\u001b[0m, in \u001b[0;36mMultiAgentPolicyManager.__init__\u001b[0;34m(self, policies, env, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(action_space\u001b[39m=\u001b[39menv\u001b[39m.\u001b[39maction_space, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     28\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     \u001b[39mlen\u001b[39m(policies) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(env\u001b[39m.\u001b[39magents)\n\u001b[1;32m     30\u001b[0m ), \u001b[39m\"\u001b[39m\u001b[39mOne policy must be assigned for each agent.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_idx \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49magent_idx\n\u001b[1;32m     33\u001b[0m \u001b[39mfor\u001b[39;00m i, policy \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(policies):\n\u001b[1;32m     34\u001b[0m     \u001b[39m# agent_id 0 is reserved for the environment proxy\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[39m# (this MultiAgentPolicyManager)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     policy\u001b[39m.\u001b[39mset_agent_id(env\u001b[39m.\u001b[39magents[i])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'raw_env' object has no attribute 'agent_idx'"
     ]
    }
   ],
   "source": [
    "policy = MultiAgentPolicyManager([RandomPolicy() for _ in range(10)], env)\n",
    "env = DummyVectorEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
