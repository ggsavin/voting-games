{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from voting_games.werewolf_env_v0 import plurality_env, pare, Phase, Roles\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from notebooks.learning_agents.models import ActorCriticAgent\n",
    "from notebooks.learning_agents.utils import play_recurrent_game\n",
    "from notebooks.learning_agents.static_agents import random_approval_wolf, random_plurality_wolf\n",
    "import notebooks.learning_agents.stats as indicators \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gameplay Indicators\n",
    "\n",
    "Now that we have trained agents, we want to see what kind of indicators possibly match up with learned voting behaviors, and how explainable they are. We do this for both plurality and approval voting mechanisms. \n",
    "\n",
    "\n",
    "```{note}\n",
    "The way the environment stores history is slightly different than observations. Whereas the latter stores the prior votes, env.history steps have the votes and the outcomes that occured at that particular day/phase/round.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load up data\n",
    "\n",
    "We are going to use replays from our trained agents to investigate these various markers. 1000 games of each voting type will be used.\n",
    "\n",
    "### Plurality Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained villagers won 486 games\n",
      "Untrained villagers won 47 games\n"
     ]
    }
   ],
   "source": [
    "env = plurality_env(num_agents=10, werewolves=2, num_accusations=2)\n",
    "observations, _, _, _, _ = env.reset()\n",
    "\n",
    "obs_size= env.convert_obs(observations['player_0']['observation']).shape[-1]\n",
    "\n",
    "untrained_plurality_agent = ActorCriticAgent({\"rec_hidden_size\": 128, \n",
    "                                        \"rec_layers\": 1,\n",
    "                                        \"joint_mlp_size\": 128,\n",
    "                                        \"split_mlp_size\": 128,\n",
    "                                        \"num_votes\": 1,\n",
    "                                        \"approval_states\": 10},\n",
    "                                        num_players=10,\n",
    "                                        obs_size=obs_size)\n",
    "\n",
    "trained_plurality_agent = ActorCriticAgent({\"rec_hidden_size\": 128,\n",
    "                                        \"rec_layers\": 1, \n",
    "                                        \"joint_mlp_size\": 128,\n",
    "                                        \"split_mlp_size\": 128,\n",
    "                                        \"num_votes\": 1,\n",
    "                                        \"approval_states\": 10},\n",
    "                                        num_players=10,\n",
    "                                        obs_size=obs_size)\n",
    "trained_plurality_agent.load_state_dict(torch.load(\"stored_agents/lstm_first_no_one_hot_128_128/plurality_agent_10_score_46\"))\n",
    "\n",
    "# random_agent = None\n",
    "\n",
    "trained_plurality_wins, trained_plurality_replays = play_recurrent_game(env, random_plurality_wolf, trained_plurality_agent, num_times=1000, hidden_state_size=128, voting_type=\"plurality\")\n",
    "untrained_plurality_wins, untrained_plurality_replays = play_recurrent_game(env, random_plurality_wolf, untrained_plurality_agent, num_times=1000, hidden_state_size=128, voting_type=\"plurality\")\n",
    "# random_wins, random_replays = play_recurrent_game_w_replays(env, random_coordinated_single_wolf, random_agent, num_times=1000, hidden_state_size=128, voting_type=\"plurality\")\n",
    "\n",
    "trained_plurality_villager_wins = [r for r in trained_plurality_replays if r[-1][\"winners\"] == Roles.VILLAGER]\n",
    "print(f'Trained villagers won {trained_plurality_wins} games')\n",
    "untrained_plurality_villager_wins = [r for r in untrained_plurality_replays if r[-1][\"winners\"] == Roles.VILLAGER]\n",
    "print(f'Untrained villagers won {untrained_plurality_wins} games')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approval Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained villagers won 507 games\n",
      "Untrained villagers won 62 games\n"
     ]
    }
   ],
   "source": [
    "env = pare(num_agents=10, werewolves=2, num_accusations=2)\n",
    "observations, _, _, _, _ = env.reset()\n",
    "\n",
    "obs_size= env.convert_obs(observations['player_0']['observation']).shape[-1]\n",
    "observations['player_0']['observation']\n",
    "\n",
    "untrained_approval_agent = ActorCriticAgent({\"rec_hidden_size\": 256, \n",
    "                                        \"rec_layers\": 1,\n",
    "                                        \"joint_mlp_size\": 128,\n",
    "                                        \"split_mlp_size\": 128,\n",
    "                                        \"num_votes\": 10,\n",
    "                                        \"approval_states\": 3},\n",
    "                                        num_players=10,\n",
    "                                        obs_size=obs_size)\n",
    "\n",
    "trained_approval_agent = ActorCriticAgent({\"rec_hidden_size\": 256,\n",
    "                                        \"rec_layers\": 1, \n",
    "                                        \"joint_mlp_size\": 128,\n",
    "                                        \"split_mlp_size\": 128,\n",
    "                                        \"num_votes\": 10,\n",
    "                                        \"approval_states\": 3},\n",
    "                                        num_players=10,\n",
    "                                        obs_size=obs_size)\n",
    "trained_approval_agent.load_state_dict(torch.load(\"stored_agents/lstm_first_no_one_hot_256_128/approval_agent_10_score_49\"))\n",
    "\n",
    "# random_agent = None\n",
    "\n",
    "trained_approval_wins, trained_approval_replays = play_recurrent_game(env, random_approval_wolf, trained_approval_agent, num_times=1000, hidden_state_size=256, voting_type=\"approval\")\n",
    "untrained_approval_wins, untrained_approval_replays = play_recurrent_game(env, random_approval_wolf, untrained_approval_agent, num_times=1000, hidden_state_size=256, voting_type=\"approval\")\n",
    "# random_wins, random_replays = play_recurrent_game_w_replays(env, random_coordinated_single_wolf, random_agent, num_times=1000, hidden_state_size=128, voting_type=\"plurality\")\n",
    "\n",
    "trained_approval_villager_wins = [r for r in trained_approval_replays if r[-1][\"winners\"] == Roles.VILLAGER]\n",
    "print(f'Trained villagers won {trained_approval_wins} games')\n",
    "untrained_approval_villager_wins = [r for r in untrained_approval_replays if r[-1][\"winners\"] == Roles.VILLAGER]\n",
    "print(f'Untrained villagers won {untrained_approval_wins} games')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days elapsed before a villager win\n",
    "\n",
    "Looking at the average amount of days elapsed before villagers win is a metric that highlights positive learning and collaboration trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average amount of days until a win is achieved by villagers in plurality games\n",
      "\t Trained villagers : 2.987368\n",
      "\t Untrained villagers : 3.076923\n",
      "\n",
      "\n",
      "Average amount of days until a win is achieved by villagers in approval games\n",
      "\t Trained villagers : 2.970833\n",
      "\t Untrained villagers : 3.376471\n"
     ]
    }
   ],
   "source": [
    "print(\"Average amount of days until a win is achieved by villagers in plurality games\")\n",
    "print(f'\\t Trained villagers : {np.mean([villager_win[-1][\"day\"] for villager_win in trained_plurality_villager_wins]):2f}')\n",
    "print(f'\\t Untrained villagers : {np.mean([villager_win[-1][\"day\"] for villager_win in untrained_plurality_villager_wins]):2f}')\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average amount of days until a win is achieved by villagers in approval games\")\n",
    "print(f'\\t Trained villagers : {np.mean([villager_win[-1][\"day\"] for villager_win in trained_approval_villager_wins]):2f}')\n",
    "print(f'\\t Untrained villagers : {np.mean([villager_win[-1][\"day\"] for villager_win in untrained_approval_villager_wins]):2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days between wolf executions\n",
    "\n",
    "Looking at the distance in days between wolf executions also highlights positive trends in learning and collaboration, as the lower the number, the more likely villagers were able to confidently coordinate and identify the wolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average amount of days until the next wolf was killed in plurality games for 2 wolf environments\n",
      "\tDays between wolf kills for trained agents : 1.581\n",
      "\tDays between wolf kills for untrained agents : 1.667\n",
      "\n",
      "\n",
      "Average amount of days until the next wolf was killed in approval games for 2 wolf environments\n",
      "\tDays between wolf kills for trained agents : 1.448\n",
      "\tDays between wolf kills for untrained agents : 1.659\n"
     ]
    }
   ],
   "source": [
    "print(\"Average amount of days until the next wolf was killed in plurality games for 2 wolf environments\")\n",
    "wolf_execution_days = \\\n",
    "    [indicators._when_did_wolves_get_killed(trained_villager_win) for trained_villager_win in trained_plurality_villager_wins]\n",
    "wolf_execution_duration_between = [b-a for a,b in wolf_execution_days]\n",
    "print(f'\\tDays between wolf kills for trained agents : {np.mean(wolf_execution_duration_between):.3f}')\n",
    "\n",
    "wolf_execution_days = \\\n",
    "    [indicators._when_did_wolves_get_killed(untrained_villager_win) for untrained_villager_win in untrained_plurality_villager_wins]\n",
    "wolf_execution_duration_between = [b-a for a,b in wolf_execution_days]\n",
    "print(f'\\tDays between wolf kills for untrained agents : {np.mean(wolf_execution_duration_between):.3f}')\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average amount of days until the next wolf was killed in approval games for 2 wolf environments\")\n",
    "wolf_execution_days = \\\n",
    "    [indicators._when_did_wolves_get_killed(trained_villager_win) for trained_villager_win in trained_approval_villager_wins]\n",
    "wolf_execution_duration_between = [b-a for a,b in wolf_execution_days]\n",
    "print(f'\\tDays between wolf kills for trained agents : {np.mean(wolf_execution_duration_between):.3f}')\n",
    "\n",
    "wolf_execution_days = \\\n",
    "    [indicators._when_did_wolves_get_killed(untrained_villager_win) for untrained_villager_win in untrained_approval_villager_wins]\n",
    "wolf_execution_duration_between = [b-a for a,b in wolf_execution_days]\n",
    "print(f'\\tDays between wolf kills for untrained agents : {np.mean(wolf_execution_duration_between):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targetting Indicators\n",
    "\n",
    "Picking the right indicators to try and describe targetting behavior is not straightforward, and differs between plurality and approval voting. Below are the ones currently chosen for both game types, along with a rendering of them across days and phases in a randomly selected game.\n",
    "\n",
    "For further analysis, we also use `indicators._game_avg_records(replays,indicator_function)` to average these values across phases and days for every replay.\n",
    "\n",
    "#### Plurality\n",
    "\n",
    "To try an make sense of targetting, we chose to look at:\n",
    "- Ratio of unique villager targets\n",
    "- Ratio of villagers voting for themselves\n",
    "- Percentage of villagers targetting dead players\n",
    "- Percentage of villager votes targetting wolves and dead wolves\n",
    "\n",
    "These should be good enough to indicate cooperation as well as general role comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wolves : ['player_0', 'player_3']\n",
      "\n",
      "Day : 1 | Phase : 0 | Round : 0\n",
      "Villager votes : [9, 9, 9, 3, 9, 9, 5, 2]\n",
      "\t | - Ratio of unique players targetted : 0.5\n",
      "\t | - 0.125 of the votes targetting wolves\n",
      "\t | - 0.125 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 1 | Phase : 0 | Round : 1\n",
      "Villager votes : [3, 9, 9, 7, 7, 8, 6, 7]\n",
      "\t | - Ratio of unique players targetted : 0.625\n",
      "\t | - 0.125 of the votes targetting wolves\n",
      "\t | - 0.125 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 1 | Phase : 1 | Round : 0\n",
      "Villager votes : [2, 8, 9, 8, 9, 0, 3, 8]\n",
      "\t | - Ratio of unique players targetted : 0.625\n",
      "\t | - 0.250 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 2 | Phase : 0 | Round : 0\n",
      "Villager votes : [9, 6, 9, 8, 3, 8]\n",
      "\t | - Ratio of unique players targetted : 0.6666666666666666\n",
      "\t | - 0.167 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.333 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 2 | Phase : 0 | Round : 1\n",
      "Villager votes : [8, 3, 3, 8, 3, 8]\n",
      "\t | - Ratio of unique players targetted : 0.3333333333333333\n",
      "\t | - 0.500 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 2 | Phase : 1 | Round : 0\n",
      "Villager votes : [7, 3, 0, 0, 0, 0]\n",
      "\t | - Ratio of unique players targetted : 0.5\n",
      "\t | - 0.833 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 3 | Phase : 0 | Round : 0\n",
      "Villager votes : [3, 8, 8, 0, 9]\n",
      "\t | - Ratio of unique players targetted : 0.8\n",
      "\t | - 0.400 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.400 share of villager votes targetting dead players\n",
      "\t | - 0.200 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 3 | Phase : 0 | Round : 1\n",
      "Villager votes : [8, 7, 3, 3, 8]\n",
      "\t | - Ratio of unique players targetted : 0.6\n",
      "\t | - 0.400 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 3 | Phase : 1 | Round : 0\n",
      "Villager votes : [3, 3, 6, 3, 6]\n",
      "\t | - Ratio of unique players targetted : 0.4\n",
      "\t | - 0.600 of the votes targetting wolves\n",
      "\t | - 0.2 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n"
     ]
    }
   ],
   "source": [
    "record = indicators._plurality_target_indicators(trained_plurality_villager_wins[0], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approval\n",
    "\n",
    "Because of the extra dimensions and expressability of approval voting, trying to determine behavior for these agents is much harder. We thus collect many different and interelated indicators to see what combinations of them might give us the most insight.\n",
    "\n",
    "The ones we are currently looking at are:\n",
    "- average target count\n",
    "- average like count\n",
    "- average neutral count\n",
    "- average self target \n",
    "- average self like\n",
    "- percentage of wolves in top targets\n",
    "- percentage of wolves in top likes\n",
    "- percent of votes targetting dead players\n",
    "- percent of votes targetting wolves by tracking:\n",
    "    - percent of votes targetting dead wolves\n",
    "    - percent of votes targetting wolves that are still alive\n",
    "- percent of likes towards wolves by tracking:\n",
    "    - percent of likes for dead wolves\n",
    "    - percent of likes for wolves that are still alive\n",
    "- percent of likes towards villagers by tracking:\n",
    "    - percent of likes towards dead villagers\n",
    "    - perceent of likes towards villagers that are still alive\n",
    "\n",
    "There might be more complicated tracking indicators that look at changes in between targets, however these have not been implemented yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day : 1 | Phase : 0 - Accusation Phase | Round : 0\n",
      "\t | - avg targetted 3.75, liked 3.00, neutral 3.25\n",
      "\t | - 0.50 share of villagers targeted themselves, and 0.38 liked themselves\n",
      "\t | - 0.0 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.00\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.20)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.17)\n",
      "\t | - % of likes towards dead villagers (0.00), and towards living villagers (0.83)\n",
      "\n",
      "\n",
      "Day : 1 | Phase : 0 - Accusation Phase | Round : 1\n",
      "\t | - avg targetted 2.62, liked 3.38, neutral 4.00\n",
      "\t | - 0.12 share of villagers targeted themselves, and 0.38 liked themselves\n",
      "\t | - 0.3333333333333333 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.00\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.24)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.19)\n",
      "\t | - % of likes towards dead villagers (0.00), and towards living villagers (0.81)\n",
      "\n",
      "\n",
      "Day : 1 | Phase : 1 - Voting Phase | Round : 0\n",
      "\t | - avg targetted 3.25, liked 3.25, neutral 3.50\n",
      "\t | - 0.25 share of villagers targeted themselves, and 0.25 liked themselves\n",
      "\t | - 0.0 wolves targetted in top votes\n",
      "\t | - 0.5 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.00\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.12)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.31)\n",
      "\t | - % of likes towards dead villagers (0.00), and towards living villagers (0.69)\n",
      "\n",
      "\n",
      "Day : 2 | Phase : 0 - Accusation Phase | Round : 0\n",
      "\t | - avg targetted 3.33, liked 3.83, neutral 2.83\n",
      "\t | - 0.33 share of villagers targeted themselves, and 0.50 liked themselves\n",
      "\t | - 0.5 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.25\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.20)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.17)\n",
      "\t | - % of likes towards dead villagers (0.17), and towards living villagers (0.65)\n",
      "\n",
      "\n",
      "Day : 2 | Phase : 0 - Accusation Phase | Round : 1\n",
      "\t | - avg targetted 3.00, liked 4.00, neutral 3.00\n",
      "\t | - 0.33 share of villagers targeted themselves, and 0.50 liked themselves\n",
      "\t | - 0.5 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.22\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.22)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.21)\n",
      "\t | - % of likes towards dead villagers (0.17), and towards living villagers (0.62)\n",
      "\n",
      "\n",
      "Day : 2 | Phase : 1 - Voting Phase | Round : 0\n",
      "\t | - avg targetted 3.17, liked 3.17, neutral 3.67\n",
      "\t | - 0.17 share of villagers targeted themselves, and 0.33 liked themselves\n",
      "\t | - 0.5 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.32\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.37)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.11)\n",
      "\t | - % of likes towards dead villagers (0.16), and towards living villagers (0.74)\n",
      "\n",
      "\n",
      "Day : 3 | Phase : 0 - Accusation Phase | Round : 0\n",
      "\t | - avg targetted 4.25, liked 3.25, neutral 2.50\n",
      "\t | - 0.00 share of villagers targeted themselves, and 0.75 liked themselves\n",
      "\t | - 0.0 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.65\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.18)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.15)\n",
      "\t | - % of likes towards dead villagers (0.08), and towards living villagers (0.77)\n",
      "\n",
      "\n",
      "Day : 3 | Phase : 0 - Accusation Phase | Round : 1\n",
      "\t | - avg targetted 2.50, liked 3.25, neutral 4.25\n",
      "\t | - 0.00 share of villagers targeted themselves, and 0.50 liked themselves\n",
      "\t | - 1.0 wolves targetted in top votes\n",
      "\t | - 0.5 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.30\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.50)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.23)\n",
      "\t | - % of likes towards dead villagers (0.31), and towards living villagers (0.46)\n",
      "\n",
      "\n",
      "Day : 3 | Phase : 1 - Voting Phase | Round : 0\n",
      "\t | - avg targetted 3.25, liked 2.25, neutral 4.50\n",
      "\t | - 0.00 share of villagers targeted themselves, and 0.00 liked themselves\n",
      "\t | - 1.0 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.38\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.46)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.11)\n",
      "\t | - % of likes towards dead villagers (0.56), and towards living villagers (0.33)\n",
      "\n",
      "\n",
      "Day : 4 | Phase : 0 - Accusation Phase | Round : 0\n",
      "\t | - avg targetted 3.33, liked 3.67, neutral 3.00\n",
      "\t | - 0.33 share of villagers targeted themselves, and 0.67 liked themselves\n",
      "\t | - 0.0 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.50\n",
      "\t | - % of votes for dead wolves (0.10), and towards living wolves (0.20)\n",
      "\t | - % of likes towards dead wolves (0.18) and towards living wolves (0.09)\n",
      "\t | - % of likes towards dead villagers (0.36), and towards living villagers (0.36)\n",
      "\n",
      "\n",
      "Day : 4 | Phase : 0 - Accusation Phase | Round : 1\n",
      "\t | - avg targetted 4.00, liked 2.00, neutral 4.00\n",
      "\t | - 0.00 share of villagers targeted themselves, and 0.00 liked themselves\n",
      "\t | - 0.0 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.75\n",
      "\t | - % of votes for dead wolves (0.17), and towards living wolves (0.17)\n",
      "\t | - % of likes towards dead wolves (0.17) and towards living wolves (0.17)\n",
      "\t | - % of likes towards dead villagers (0.33), and towards living villagers (0.33)\n",
      "\n",
      "\n",
      "Day : 4 | Phase : 1 - Voting Phase | Round : 0\n",
      "\t | - avg targetted 3.00, liked 4.33, neutral 2.67\n",
      "\t | - 0.33 share of villagers targeted themselves, and 0.33 liked themselves\n",
      "\t | - 0.5 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.56\n",
      "\t | - % of votes for dead wolves (0.11), and towards living wolves (0.22)\n",
      "\t | - % of likes towards dead wolves (0.08) and towards living wolves (0.08)\n",
      "\t | - % of likes towards dead villagers (0.46), and towards living villagers (0.38)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = indicators._approval_target_indicators(trained_approval_villager_wins[0], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ties\n",
    "\n",
    "Ties are quite common, and could possibly be used strategically. Knowning when/if ties are occuring could possibly lead to a better understanding of agent voting patterns.\n",
    "\n",
    "What we are currenly looking for is:\n",
    "- What percentage of voting rounds are ties?\n",
    "- How often do ties in accusation rounds lead to ties in voting rounds?\n",
    "- If a wolf gets lucky and survives a tied voting round, how likey is it they get executed the next voting round?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two functions we use to achieve this:\n",
    "- `indicators._game_tie_info(game_replay, voting_type=None)` which returns if there was a tie, if and which wolf was targetted, and if a wolf died during the phase. This is done for every day and every phase in a game\n",
    "- `indicators._process_tie_info(tie_records)` takes the results above and returns:\n",
    "    - percentage of ties in accusation phases per game\n",
    "    - percentage of ties in voting phases per game\n",
    "    - likelihood of a tie in a voting phase given a tie in the prior accusation phases\n",
    "    - likelihood of a wolf getting targetting in a subsequent voting round after getting lucky and surviving a tie round where they were a target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plurality tie indicators\n",
      "\tLikelihood of ties in accusation phases : 0.29\n",
      "\tLikelihood of ties in voting phases : 0.19\n",
      "\tLikelihood of a tie in a voting phase given a tie in the prior accusation phases 0.21\n",
      "\tLikelihood of a wolf getting targetting in a subsequent voting round if they survived a tie : 0.77\n",
      "\n",
      "\n",
      "Approval tie indicators\n",
      "\tLikelihood of ties in accusation phases : 0.36\n",
      "\tLikelihood of ties in voting phases : 0.31\n",
      "\tLikelihood of a tie in a voting phase given a tie in the prior accusation phases 0.32\n",
      "\tLikelihood of a wolf getting targetting in a subsequent voting round if they survived a tie : 0.63\n"
     ]
    }
   ],
   "source": [
    "tgps = \\\n",
    "    np.nanmean(np.stack([indicators._process_tie_info(indicators._game_tie_info(trained_villager_win, voting_type=\"plurality\")) for trained_villager_win in trained_plurality_villager_wins]),axis= 0)\n",
    "tgas = \\\n",
    "    np.nanmean(np.stack([indicators._process_tie_info(indicators._game_tie_info(trained_villager_win, voting_type=\"approval\")) for trained_villager_win in trained_approval_villager_wins]), axis=0)\n",
    "\n",
    "print(\"Plurality tie indicators\")\n",
    "print(f'\\tLikelihood of ties in accusation phases : {tgps[0]:.2f}')\n",
    "print(f'\\tLikelihood of ties in voting phases : {tgps[1]:.2f}')\n",
    "print(f'\\tLikelihood of a tie in a voting phase given a tie in the prior accusation phases {tgps[2]:.2f}')\n",
    "print(f'\\tLikelihood of a wolf getting targetting in a subsequent voting round if they survived a tie : {tgps[3]:.2f}')\n",
    "print(\"\\n\")\n",
    "print(\"Approval tie indicators\")\n",
    "print(f'\\tLikelihood of ties in accusation phases : {tgas[0]:.2f}')\n",
    "print(f'\\tLikelihood of ties in voting phases : {tgas[1]:.2f}')\n",
    "print(f'\\tLikelihood of a tie in a voting phase given a tie in the prior accusation phases {tgas[2]:.2f}')\n",
    "print(f'\\tLikelihood of a wolf getting targetting in a subsequent voting round if they survived a tie : {tgas[3]:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
