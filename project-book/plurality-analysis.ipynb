{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from voting_games.werewolf_env_v0 import plurality_env, Roles, Phase\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plurality Voting\n",
    "\n",
    "Blurb on plurality voting goes here...\n",
    "\n",
    "We want to see how an static agents vs static wolves fare, before training our PPO agents to hopefully learn to do better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training Baselines\n",
    "\n",
    "To properly asses our agents, we need baselines. For this purpose we have totally random villagers and semi-random villagers that will only vote for agents that are currently alive.\n",
    "\n",
    "As for wolves, we have the following behaviors:\n",
    "- wolves that coordinate and each target one villager\n",
    "- random wolves that do whatever\n",
    "- revenge wolves that coordinate and target a random villager that targetted a wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revenge_coordinated_wolf(env, agent, action = None):\n",
    "    villagers_remaining = set(env.world_state[\"villagers\"]) & set(env.world_state['alive'])\n",
    "    wolves_remaining = set(env.world_state[\"werewolves\"]) & set(env.world_state['alive'])\n",
    "\n",
    "    # who tried to vote out a wolf last time?\n",
    "    # TODO : just get this from the observations\n",
    "\n",
    "    prev_votes = env.history[-1]['votes']\n",
    "    villagers_targetting_wolves = [player for player in prev_votes if f'player_{prev_votes[player]}' in wolves_remaining]\n",
    "    # target = random.choice(list(villagers_remaining))\n",
    "    # pick \n",
    "    if action != None:\n",
    "        return action\n",
    "    \n",
    "    if len(villagers_targetting_wolves) == 0:\n",
    "        return int(random.choice(list(villagers_remaining)).split(\"_\")[-1])\n",
    "    \n",
    "    return int(random.choice(list(villagers_targetting_wolves)).split(\"_\")[-1])\n",
    "\n",
    "def revenge_wolf(env, agent, action = None):\n",
    "    villagers_remaining = set(env.world_state[\"villagers\"]) & set(env.world_state['alive'])\n",
    "\n",
    "    prev_votes = env.history[-1]['votes']\n",
    "    villagers_targetting_you = [player for player in prev_votes if f'player_{prev_votes[player]}' == agent]\n",
    "    if len(villagers_targetting_you) > 0:\n",
    "        return int(random.choice(list(villagers_targetting_you)).split(\"_\")[-1])\n",
    "    \n",
    "    return int(random.choice(list(villagers_remaining)).split(\"_\")[-1])\n",
    "\n",
    "def random_single_target_villager(env, agent, action=None):\n",
    "    targets = set(env.world_state[\"alive\"]) - set([agent])\n",
    "    return int(random.choice(list(targets)).split(\"_\")[-1])\n",
    "\n",
    "def random_single_target_coordinated_villager(env, agent, action=None):\n",
    "    targets = set(env.world_state[\"alive\"]) - set([agent])\n",
    "    return action if action != None else int(random.choice(list(targets)).split(\"_\")[-1])\n",
    "\n",
    "# random_coordinated_wolf(env)\n",
    "def random_agent_action(env, agent, action=None):\n",
    "   return env.action_space(agent).sample()\n",
    "\n",
    "def random_coordinated_single_wolf(env, agent, action=None):\n",
    "    villagers_remaining = set(env.world_state[\"villagers\"]) & set(env.world_state['alive'])\n",
    "    return action if action != None else int(random.choice(list(villagers_remaining)).split(\"_\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_static_wolf_game(env, wolf_policy, villager_agent, num_times=100):\n",
    "\n",
    "    villager_wins = 0\n",
    "    game_replays = []\n",
    "    for _ in range(num_times):\n",
    "        observations, rewards, terminations, truncations, infos = env.reset()\n",
    "        \n",
    "        wolf_action = None\n",
    "        villager_action = None\n",
    "        while env.agents:\n",
    "            actions = {}\n",
    "\n",
    "            villagers = set(env.agents) & set(env.world_state[\"villagers\"])\n",
    "            wolves = set(env.agents) & set(env.world_state[\"werewolves\"])\n",
    "\n",
    "            # villager steps\n",
    "            for villager in villagers:\n",
    "                villager_action = villager_agent(env, villager, action=villager_action)\n",
    "                actions[villager] = villager_action\n",
    "\n",
    "            # wolf steps\n",
    "            phase = env.world_state['phase']\n",
    "            for wolf in wolves:\n",
    "                wolf_action = wolf_policy(env, wolf, action=wolf_action)\n",
    "                actions[wolf] = wolf_action\n",
    "        \n",
    "            observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "\n",
    "            if env.world_state['phase'] == Phase.NIGHT:\n",
    "                wolf_action = None\n",
    "            \n",
    "            if env.world_state['phase'] == Phase.ACCUSATION and phase == Phase.NIGHT:\n",
    "                wolf_action = None\n",
    "\n",
    "            # If we care to use villager action\n",
    "            villager_action = None\n",
    "\n",
    "        winner = env.world_state['winners']\n",
    "        if winner == Roles.VILLAGER:\n",
    "            villager_wins += 1\n",
    "\n",
    "        game_replays.append(copy.deepcopy(env.history))\n",
    "\n",
    "    return villager_wins, game_replays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 players, with 2 wolves\n",
      "\n",
      "Wolf Strategy                 Semi-Smart Villager    Totally Random Villager    Coordinated Random Villagers\n",
      "--------------------------  ---------------------  -------------------------  ------------------------------\n",
      "Coordinated Wolves                          0.125                      0.042                           0.275\n",
      "Random Wolves                               0.671                      0.591                           0.665\n",
      "Coorindated revenge wolves                  0.22                       0.086                           0.308\n",
      "Revenge wolves                              0.225                      0.07                            0.252\n",
      "\n",
      "\n",
      "15 players, with 3 wolves\n",
      "\n",
      "Wolf Strategy                 Semi-Smart Villager    Totally Random Villager    Coordinated Random Villagers\n",
      "--------------------------  ---------------------  -------------------------  ------------------------------\n",
      "Coordinated Wolves                          0.027                      0.002                           0.395\n",
      "Random Wolves                               0.739                      0.575                           0.719\n",
      "Coorindated revenge wolves                  0.082                      0.013                           0.389\n",
      "Revenge wolves                              0.144                      0.024                           0.393\n"
     ]
    }
   ],
   "source": [
    "env = plurality_env(num_agents=10, werewolves=2, num_accusations=1)\n",
    "env.reset()\n",
    "print(f'10 players, with 2 wolves\\n')\n",
    "\n",
    "revenge_coordinated_wolves = []\n",
    "revenge_coordinated_wolves.append(play_static_wolf_game(env, revenge_coordinated_wolf, random_single_target_villager, num_times=1000)[0]/1000.0)\n",
    "revenge_coordinated_wolves.append(play_static_wolf_game(env, revenge_coordinated_wolf, random_agent_action, num_times=1000)[0]/1000.0)\n",
    "revenge_coordinated_wolves.append(play_static_wolf_game(env, revenge_coordinated_wolf, random_single_target_coordinated_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "revenge_wolves = []\n",
    "revenge_wolves.append(play_static_wolf_game(env, revenge_wolf, random_single_target_villager, num_times=1000)[0]/1000.0)\n",
    "revenge_wolves.append(play_static_wolf_game(env, revenge_wolf, random_agent_action, num_times=1000)[0]/1000.0)\n",
    "revenge_wolves.append(play_static_wolf_game(env, revenge_wolf, random_single_target_coordinated_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "coordinated_wolves = []\n",
    "coordinated_wolves.append(play_static_wolf_game(env, random_coordinated_single_wolf, random_single_target_villager, num_times=1000)[0]/1000.0)\n",
    "coordinated_wolves.append(play_static_wolf_game(env, random_coordinated_single_wolf, random_agent_action, num_times=1000)[0]/1000.0)\n",
    "coordinated_wolves.append(play_static_wolf_game(env, random_coordinated_single_wolf, random_single_target_coordinated_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "random_wolves = []\n",
    "random_wolves.append(play_static_wolf_game(env, random_agent_action, random_single_target_villager, num_times=1000)[0]/1000.0)\n",
    "random_wolves.append(play_static_wolf_game(env, random_agent_action, random_agent_action, num_times=1000)[0]/1000.0)\n",
    "random_wolves.append(play_static_wolf_game(env, random_agent_action, random_single_target_coordinated_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "print(tabulate([['Coordinated Wolves', *coordinated_wolves], ['Random Wolves', *random_wolves], ['Coorindated revenge wolves', *revenge_coordinated_wolves], ['Revenge wolves', *revenge_wolves]], \n",
    "               headers=[\"Wolf Strategy\", \"Semi-Smart Villager\", \"Totally Random Villager\", \"Coordinated Random Villagers\"]))\n",
    "\n",
    "print(\"\\n\")\n",
    "env = plurality_env(num_agents=15, werewolves=3, num_accusations=1)\n",
    "env.reset()\n",
    "print(f'15 players, with 3 wolves\\n')\n",
    "\n",
    "revenge_coordinated_wolves = []\n",
    "revenge_coordinated_wolves.append(play_static_wolf_game(env, revenge_coordinated_wolf, random_single_target_villager, num_times=1000)[0]/1000.0)\n",
    "revenge_coordinated_wolves.append(play_static_wolf_game(env, revenge_coordinated_wolf, random_agent_action, num_times=1000)[0]/1000.0)\n",
    "revenge_coordinated_wolves.append(play_static_wolf_game(env, revenge_coordinated_wolf, random_single_target_coordinated_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "revenge_wolves = []\n",
    "revenge_wolves.append(play_static_wolf_game(env, revenge_wolf, random_single_target_villager, num_times=1000)[0]/1000.0)\n",
    "revenge_wolves.append(play_static_wolf_game(env, revenge_wolf, random_agent_action, num_times=1000)[0]/1000.0)\n",
    "revenge_wolves.append(play_static_wolf_game(env, revenge_wolf, random_single_target_coordinated_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "coordinated_wolves = []\n",
    "coordinated_wolves.append(play_static_wolf_game(env, random_coordinated_single_wolf, random_single_target_villager, num_times=1000)[0]/1000.0)\n",
    "coordinated_wolves.append(play_static_wolf_game(env, random_coordinated_single_wolf, random_agent_action, num_times=1000)[0]/1000.0)\n",
    "coordinated_wolves.append(play_static_wolf_game(env, random_coordinated_single_wolf, random_single_target_coordinated_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "random_wolves = []\n",
    "random_wolves.append(play_static_wolf_game(env, random_agent_action, random_single_target_villager, num_times=1000)[0]/1000.0)\n",
    "random_wolves.append(play_static_wolf_game(env, random_agent_action, random_agent_action, num_times=1000)[0]/1000.0)\n",
    "random_wolves.append(play_static_wolf_game(env, random_agent_action, random_single_target_coordinated_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "print(tabulate([['Coordinated Wolves', *coordinated_wolves], ['Random Wolves', *random_wolves], ['Coorindated revenge wolves', *revenge_coordinated_wolves], ['Revenge wolves', *revenge_wolves]], \n",
    "               headers=[\"Wolf Strategy\", \"Semi-Smart Villager\", \"Totally Random Villager\", \"Coordinated Random Villagers\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
