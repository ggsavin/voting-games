{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from voting_games.werewolf_env_v0 import plurality_env, Roles, Phase\n",
    "from notebooks.learning_agents.models import ActorCriticAgent\n",
    "from notebooks.learning_agents.utils import play_static_game, play_recurrent_game\n",
    "from notebooks.learning_agents.static_agents import (\n",
    "    random_plurality_villager, \n",
    "    random_coordinated_plurality_villager, \n",
    "    random_agent,\n",
    "    random_plurality_wolf,\n",
    "    revenge_plurality_wolf,\n",
    "    coordinated_revenge_plurality_wolf)\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plurality Voting\n",
    "\n",
    "Blurb on plurality voting goes here...\n",
    "\n",
    "We want to see how an static agents vs static wolves fare, before training our PPO agents to hopefully learn to do better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training Baselines\n",
    "\n",
    "To properly asses our agents, we need baselines. For this purpose we have totally random villagers and semi-random villagers that will only vote for agents that are currently alive.\n",
    "\n",
    "As for wolves, we have the following behaviors:\n",
    "- wolves that coordinate and each target one villager\n",
    "- random wolves that do whatever\n",
    "- revenge wolves that coordinate and target a random villager that targetted a wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'stored_agents/lstm_first_no_one_hot_128_128/plurality_agent_10_score_46'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m      4\u001b[0m obs_size\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mconvert_obs(observations[\u001b[39m'\u001b[39m\u001b[39mplayer_0\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mobservation\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m trained_plurality_agent \u001b[39m=\u001b[39m ActorCriticAgent({\u001b[39m\"\u001b[39m\u001b[39mrec_hidden_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m128\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                         \u001b[39m\"\u001b[39m\u001b[39mrec_layers\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m, \n\u001b[1;32m      8\u001b[0m                                         \u001b[39m\"\u001b[39m\u001b[39mjoint_mlp_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m128\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m                                         num_players\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m     13\u001b[0m                                         obs_size\u001b[39m=\u001b[39mobs_size)\n\u001b[0;32m---> 14\u001b[0m trained_plurality_agent\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mstored_agents/lstm_first_no_one_hot_128_128/plurality_agent_10_score_46\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    271\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'stored_agents/lstm_first_no_one_hot_128_128/plurality_agent_10_score_46'"
     ]
    }
   ],
   "source": [
    "env = plurality_env(num_agents=10, werewolves=2, num_accusations=2)\n",
    "observations, _, _, _, _ = env.reset()\n",
    "\n",
    "obs_size= env.convert_obs(observations['player_0']['observation']).shape[-1]\n",
    "\n",
    "trained_plurality_agent = ActorCriticAgent({\"rec_hidden_size\": 128,\n",
    "                                        \"rec_layers\": 1, \n",
    "                                        \"joint_mlp_size\": 128,\n",
    "                                        \"split_mlp_size\": 128,\n",
    "                                        \"num_votes\": 1,\n",
    "                                        \"approval_states\": 10},\n",
    "                                        num_players=10,\n",
    "                                        obs_size=obs_size)\n",
    "trained_plurality_agent.load_state_dict(torch.load(\"../notebooks/stored_agents/lstm_first_no_one_hot_128_128/plurality_agent_10_score_46\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 players, with 2 wolves\n",
      "\n",
      "Wolf Strategy                 Semi-Smart Villager    Totally Random Villager    Coordinated Random Villagers\n",
      "--------------------------  ---------------------  -------------------------  ------------------------------\n",
      "Coordinated Wolves                          0.13                       0.05                            0.31\n",
      "Random Wolves                               0.653                      0.594                           0.711\n",
      "Coorindated revenge wolves                  0.246                      0.08                            0.297\n",
      "Revenge wolves                              0.215                      0.081                           0.329\n",
      "\n",
      "\n",
      "15 players, with 3 wolves\n",
      "\n",
      "Wolf Strategy                 Semi-Smart Villager    Totally Random Villager    Coordinated Random Villagers\n",
      "--------------------------  ---------------------  -------------------------  ------------------------------\n",
      "Coordinated Wolves                          0.029                      0.003                           0.386\n",
      "Random Wolves                               0.702                      0.592                           0.699\n",
      "Coorindated revenge wolves                  0.086                      0.017                           0.366\n",
      "Revenge wolves                              0.141                      0.031                           0.398\n"
     ]
    }
   ],
   "source": [
    "env = plurality_env(num_agents=10, werewolves=2, num_accusations=1)\n",
    "env.reset()\n",
    "print(f'10 players, with 2 wolves\\n')\n",
    "\n",
    "revenge_coordinated_wolves = []\n",
    "revenge_coordinated_wolves.append(play_static_game(env, coordinated_revenge_plurality_wolf, random_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "revenge_coordinated_wolves.append(play_static_game(env, coordinated_revenge_plurality_wolf, random_agent, num_times=1000)[0]/1000.0)\n",
    "revenge_coordinated_wolves.append(play_static_game(env, coordinated_revenge_plurality_wolf, random_coordinated_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "revenge_wolves = []\n",
    "revenge_wolves.append(play_static_game(env, revenge_plurality_wolf, random_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "revenge_wolves.append(play_static_game(env, revenge_plurality_wolf, random_agent, num_times=1000)[0]/1000.0)\n",
    "revenge_wolves.append(play_static_game(env, revenge_plurality_wolf, random_coordinated_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "coordinated_wolves = []\n",
    "coordinated_wolves.append(play_static_game(env, random_plurality_wolf, random_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "coordinated_wolves.append(play_static_game(env, random_plurality_wolf, random_agent, num_times=1000)[0]/1000.0)\n",
    "coordinated_wolves.append(play_static_game(env, random_plurality_wolf, random_coordinated_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "random_wolves = []\n",
    "random_wolves.append(play_static_game(env, random_agent, random_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "random_wolves.append(play_static_game(env, random_agent, random_agent, num_times=1000)[0]/1000.0)\n",
    "random_wolves.append(play_static_game(env, random_agent, random_coordinated_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "print(tabulate([['Coordinated Wolves', *coordinated_wolves], ['Random Wolves', *random_wolves], ['Coorindated revenge wolves', *revenge_coordinated_wolves], ['Revenge wolves', *revenge_wolves]], \n",
    "               headers=[\"Wolf Strategy\", \"Semi-Smart Villager\", \"Totally Random Villager\", \"Coordinated Random Villagers\"]))\n",
    "\n",
    "print(\"\\n\")\n",
    "env = plurality_env(num_agents=15, werewolves=3, num_accusations=1)\n",
    "env.reset()\n",
    "print(f'15 players, with 3 wolves\\n')\n",
    "\n",
    "revenge_coordinated_wolves = []\n",
    "revenge_coordinated_wolves.append(play_static_game(env, coordinated_revenge_plurality_wolf, random_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "revenge_coordinated_wolves.append(play_static_game(env, coordinated_revenge_plurality_wolf, random_agent, num_times=1000)[0]/1000.0)\n",
    "revenge_coordinated_wolves.append(play_static_game(env, coordinated_revenge_plurality_wolf, random_coordinated_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "revenge_wolves = []\n",
    "revenge_wolves.append(play_static_game(env, revenge_plurality_wolf, random_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "revenge_wolves.append(play_static_game(env, revenge_plurality_wolf, random_agent, num_times=1000)[0]/1000.0)\n",
    "revenge_wolves.append(play_static_game(env, revenge_plurality_wolf, random_coordinated_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "coordinated_wolves = []\n",
    "coordinated_wolves.append(play_static_game(env, random_plurality_wolf, random_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "coordinated_wolves.append(play_static_game(env, random_plurality_wolf, random_agent, num_times=1000)[0]/1000.0)\n",
    "coordinated_wolves.append(play_static_game(env, random_plurality_wolf, random_coordinated_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "random_wolves = []\n",
    "random_wolves.append(play_static_game(env, random_agent, random_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "random_wolves.append(play_static_game(env, random_agent, random_agent, num_times=1000)[0]/1000.0)\n",
    "random_wolves.append(play_static_game(env, random_agent, random_coordinated_plurality_villager, num_times=1000)[0]/1000.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(tabulate([['Coordinated Wolves', *coordinated_wolves], ['Random Wolves', *random_wolves], ['Coorindated revenge wolves', *revenge_coordinated_wolves], ['Revenge wolves', *revenge_wolves]], \n",
    "               headers=[\"Wolf Strategy\", \"Semi-Smart Villager\", \"Totally Random Villager\", \"Coordinated Random Villagers\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
