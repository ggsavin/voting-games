

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Terminology &#8212; Voting in Hidden Role Games</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'terminology';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Agent Implementation" href="agent-implementation.html" />
    <link rel="prev" title="Werewolf - The Implementation" href="game-implementation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/midjourney-werewolves.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/midjourney-werewolves.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    COMP 5903 - Voting in Hidden Role Games
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="game-description.html">Werewolf - The Game</a></li>
<li class="toctree-l1"><a class="reference internal" href="literature-review.html">Literature Review</a></li>
<li class="toctree-l1"><a class="reference internal" href="game-implementation.html">Werewolf - The Implementation</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Terminology</a></li>
<li class="toctree-l1"><a class="reference internal" href="agent-implementation.html">Agent Implementation</a></li>
<li class="toctree-l1"><a class="reference internal" href="training_agent_info.html">Training Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="indicators.html">Gameplay Indicators</a></li>
<li class="toctree-l1"><a class="reference internal" href="game_visualization.html">Replay visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="plurality-analysis.html">Plurality Voting</a></li>
<li class="toctree-l1"><a class="reference internal" href="approval-analysis.html">Approval Voting</a></li>
<li class="toctree-l1"><a class="reference internal" href="dicsussion.html">Discussion</a></li>
<li class="toctree-l1"><a class="reference internal" href="future.html">Future Directions</a></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ggsavin/voting-games" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ggsavin/voting-games/issues/new?title=Issue%20on%20page%20%2Fterminology.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/terminology.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Terminology</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pomdps">POMDPs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rl-marl">RL &amp; MARL</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ppo">PPO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstms">LSTMs</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="terminology">
<h1>Terminology<a class="headerlink" href="#terminology" title="Permalink to this heading">#</a></h1>
<section id="pomdps">
<h2>POMDPs<a class="headerlink" href="#pomdps" title="Permalink to this heading">#</a></h2>
<p>Partially Observable Markov Decision Processes (POMDPs<a class="footnote-reference brackets" href="#id14" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>) are a special case of a Markov Decision Process (MDP) where the agent does not have direct observability to the state, but rather gets their own, possibly unique, observation. Formally, it is a tuple consisting of:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(S\)</span>, a set of states</p></li>
<li><p><span class="math notranslate nohighlight">\(A\)</span>, a set of actions</p></li>
<li><p><span class="math notranslate nohighlight">\(T\)</span>, a set of transition probabilities between states</p></li>
<li><p><span class="math notranslate nohighlight">\(R: S \times A \rightarrow \mathbb{R}\)</span> is the rewaard function</p></li>
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span>, a set of observations</p></li>
<li><p><span class="math notranslate nohighlight">\(O\)</span>, a set of observation probabilities</p></li>
<li><p><span class="math notranslate nohighlight">\(\gamma\)</span> is a discount factor, bounded by <span class="math notranslate nohighlight">\([0,1)\)</span></p></li>
</ul>
<p>Given a current state <span class="math notranslate nohighlight">\(s \in S\)</span>, an agent will take an action <span class="math notranslate nohighlight">\(a \in A\)</span> based on some observation <span class="math notranslate nohighlight">\(o \in O\)</span> and will transition to a new state <span class="math notranslate nohighlight">\(s'\)</span> with probability <span class="math notranslate nohighlight">\(T(s'|s,a)\)</span> and receive a reward <span class="math notranslate nohighlight">\(r = R(s,a)\)</span></p>
<p>RL and MARL enviornments usually satisfy the Markov property that future states depend only on current state and action pairs, and thus can be formulated as MDPs.</p>
</section>
<section id="rl-marl">
<h2>RL &amp; MARL<a class="headerlink" href="#rl-marl" title="Permalink to this heading">#</a></h2>
<p><a class="reference internal" href="#single-rl"><span class="std std-ref">Reinforcement Learning</span></a> is a training method wherein an agent takes an action in an environment and is either rewarded or punished while transitioning to a new state. This is repeated until the agent reaches a terminal state. Ideally an agent will learn an optimal <em>policy</em> that maps observations to actions through many interactions in their environment.</p>
<p>When it comes to <a class="reference internal" href="#multi-agent-rl"><span class="std std-ref">Multi-Agent Learning</span></a>, multiple agents are either leaarning in a decentralized manner, or being directed by a central policy. The dynamic nature of of Multi-Agent systems make learning much more challenging, although certain algorithms such as PPO and DQN still work.</p>
<p>Agents can learn using value-based, policy-based and model-based algorithms. A good taxonomy of different types of algorithms can be seen in the diagram below.</p>
<figure class="align-default" id="rl-taxonomy">
<img alt="Taxonomy of RL algorithms" src="https://spinningup.openai.com/en/latest/_images/rl_algorithms_9_15.svg" /><figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Taxonomy of RL Algorithms<a class="footnote-reference brackets" href="#rl-tax" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></span><a class="headerlink" href="#rl-taxonomy" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>A good reference on RL is the timeless book <em>Reinforcement Learning: An Introduction</em><a class="footnote-reference brackets" href="#sutton-barto-book" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a> by Sutton &amp; Barto.</p>
<figure class="align-default" id="single-rl">
<img alt="single agent RL" src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*Ews7HaMiSn2l8r70eeIszQ.png" />
<figcaption>
<p><span class="caption-number">Fig. 2 </span><span class="caption-text">Single Agent Reinforcement Learning<a class="footnote-reference brackets" href="#rl-pictures" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a></span><a class="headerlink" href="#single-rl" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="multi-agent-rl">
<img alt="multi agent RL" src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*1o1oeH3vpzsfJukLbFsekw.png" />
<figcaption>
<p><span class="caption-number">Fig. 3 </span><span class="caption-text">Multi-Agent Reinforcement Learning<a class="footnote-reference brackets" href="#rl-pictures" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a></span><a class="headerlink" href="#multi-agent-rl" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="ppo">
<span id="ppo-alg-header"></span><h2>PPO<a class="headerlink" href="#ppo" title="Permalink to this heading">#</a></h2>
<p>Proxmial Policy Optimization (PPO) was chosen because it stil seems to be the most widely used on-policy algorithm and it was also used in a similar setting as our work <span id="id6">[<a class="reference internal" href="bibliography.html#id7" title="Nicolo' Brandizzi, Davide Grossi, and Luca Iocchi. Rlupus: cooperation through emergent communication in the werewolf social deduction game. ArXiv, 2021.">BGI21</a>, <a class="reference internal" href="bibliography.html#id12" title="Natsuki Matsunami, Shun Okuhara, and Takayuki Ito. Agents that learn to vote for a joint action through Multi-Agent reinforcement learning. In 2020 9th International Congress on Advanced Applied Informatics (IIAI-AAI), 832–833. September 2020.">MOI20</a>]</span>.</p>
<p>Because we are also implementing an LSTM, the action <span class="math notranslate nohighlight">\(a_t\)</span> selected by the policy <span class="math notranslate nohighlight">\(\pi_{\theta}\)</span> depends on both the observation <span class="math notranslate nohighlight">\(o_t\)</span> and the hidden state <span class="math notranslate nohighlight">\(h_t\)</span>.</p>
<p>We implemented our own following some works using a truncated BPTT <span id="id7">[<a class="reference internal" href="bibliography.html#id10" title="Marco Pleines, Matthias Pallasch, Frank Zimmer, and Mike Preuss. Memory gym: partially observable challenges to memory-based agents. In International Conference on Learning Representations. 2023. URL: https://openreview.net/forum?id=jHc8dCx6DDr.">PPZP23</a>]</span> and CLeanRL, however relying on a framework might have been a better choice.</p>
<div class="proof algorithm admonition" id="ppo-alg">
<p class="admonition-title"><span class="caption-number">Algorithm 1 </span> (Proximal Policy Optimization w/ Clipped Surrogate)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inputs</strong> Initial policy parameters <span class="math notranslate nohighlight">\(\theta_0\)</span>, clipping threshold <span class="math notranslate nohighlight">\(\epsilon\)</span></p>
<ol class="arabic">
<li><p>for <span class="math notranslate nohighlight">\(i=0,1,2,3,...\)</span> do</p>
<ol class="arabic">
<li><p>for <span class="math notranslate nohighlight">\(agent=1,2,...,N\)</span> do</p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="training_agent_info.html#fill-buffer"><span class="std std-ref">Collect set of full game trajectories</span></a> <span class="math notranslate nohighlight">\(\tau\)</span> on policy <span class="math notranslate nohighlight">\(\pi(\theta_i)\)</span>.
<strong>We store the hidden state of the recurrent layer <span class="math notranslate nohighlight">\(h\)</span> at each step of each trajectory</strong></p></li>
<li><p><a class="reference internal" href="training_agent_info.html#estimate-adv"><span class="std std-ref">Estimate advatanges</span></a> <span class="math notranslate nohighlight">\(\hat{A}^{\pi_i}_t\)</span> using GAE <span id="id8">[<a class="reference internal" href="bibliography.html#id36" title="John Schulman, Philipp Moritz, Sergey Levine, Michael Jordan, and Pieter Abbeel. High-dimensional continuous control using generalized advantage estimation. arXiv preprint arXiv:1506.02438, 2015.">SML+15</a>]</span></p></li>
</ol>
</li>
<li><p><a class="reference internal" href="training_agent_info.html#minibatch-loss"><span class="std std-ref">Compute Policy Update</span></a> using clipped surrogate <span id="id9">[<a class="reference internal" href="bibliography.html#id35" title="John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.">SWD+17</a>]</span></p>
<ol class="arabic">
<li><p><span class="math notranslate nohighlight">\(\mathcal{L}^C(\theta)\)</span> is our clipped surrogate objective function</p>
<div class="math notranslate nohighlight">
\[\begin{split}
                \mathcal{L}^C(\theta) &amp; = E [\sum_{t=0}^{\tau}[min(r_t(\theta)\hat{A}_t, clip(r_t(\theta), 1-\epsilon, 1+ \epsilon)A_t)]] \\
                r_t(\theta) &amp; = \frac{\pi_{\theta}(a_t | o_t, h_t)}{\pi_{\theta-old}(a_t | o_t, h_t)}
            \end{split}\]</div>
</li>
<li><p>Squared error loss optimization for the value function</p>
<div class="math notranslate nohighlight">
\[
                \mathcal{L}^V_t(\theta) = (V_{\theta}(o_t,h_t) - V^{target}_t)^2
            \]</div>
</li>
<li><p>Entropy bonus to promote exploitation</p>
<div class="math notranslate nohighlight">
\[
                \mathcal{H}[\pi_{\theta}](o_t, h_t)
            \]</div>
</li>
<li><p>Putting it all together with scaling coefficients <span class="math notranslate nohighlight">\(c_1, c_2\)</span> for the value loss and entropy bonus respectively</p>
<div class="math notranslate nohighlight">
\[
                L^{CVH}_t(\theta) = E [\mathcal{L}^C(\theta) - c_1\cdot \mathcal{L}^V_t(\theta) + c_2 \mathcal{H}[\pi_{\theta}](o_t, h_t)]
            \]</div>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</section>
</div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>The 37 implementation details of PPO<a class="footnote-reference brackets" href="#details-ppo" id="id10" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a> is a great blog post detailing many more intricacies of PPO implementations</p>
</div>
</section>
<section id="lstms">
<h2>LSTMs<a class="headerlink" href="#lstms" title="Permalink to this heading">#</a></h2>
<p>Long-short Term Memory (LSTM) networks are a type of deep neural network that is tailored for sequential data. They are an evolution of Recurrent Neural Networks (RNNs) that have been designed to deal with backpropagation issues and can handle much longer sequences <span id="id11">[<a class="reference internal" href="bibliography.html#id5" title="Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.">HS97</a>]</span>.</p>
<p>These types of networks have loops in them, allowing information  to persist. In the below <a class="reference internal" href="#unrolled-rnn"><span class="std std-ref">figure</span></a>, we can see what an unrolled RNN looks like, and in following <a class="reference internal" href="#lstm-internal-cell"><span class="std std-ref">figure</span></a>, we see the LSTM,along with its inner workings and different gates that the cells are composed of.</p>
<p>For our PPO Implementation, we store the hidden state <span class="math notranslate nohighlight">\(h_n\)</span> and cell state <span class="math notranslate nohighlight">\(c_n\)</span> from our LSTM output for each state/action pair taken by an agent so we can use it again the next time we want to call our model or calculate losses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A great resource to understanding LSTMs and RNNs is <a class="reference external" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">this famous blogpost</a> by Christopher Olah.</p>
</div>
<figure class="align-default" id="unrolled-rnn">
<img alt="unrolled RNN" src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png" />
<figcaption>
<p><span class="caption-number">Fig. 4 </span><span class="caption-text">An unrolled RNN highlights it’s sequential nature<a class="footnote-reference brackets" href="#understand-lstm" id="id12" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a></span><a class="headerlink" href="#unrolled-rnn" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-default" id="lstm-internal-cell">
<img alt="lstm cell" src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png" />
<figcaption>
<p><span class="caption-number">Fig. 5 </span><span class="caption-text">LSTM Cells and their internals<a class="footnote-reference brackets" href="#understand-lstm" id="id13" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a></span><a class="headerlink" href="#lstm-internal-cell" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<hr class="footnotes docutils" />
<aside class="footnote brackets" id="id14" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process">https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process</a></p>
</aside>
<aside class="footnote brackets" id="rl-tax" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html">https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html</a></p>
</aside>
<aside class="footnote brackets" id="sutton-barto-book" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="http://incompleteideas.net/book/the-book-2nd.html">http://incompleteideas.net/book/the-book-2nd.html</a></p>
</aside>
<aside class="footnote brackets" id="rl-pictures" role="note">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id4">1</a>,<a role="doc-backlink" href="#id5">2</a>)</span>
<p><a class="reference external" href="https://towardsdatascience.com/multi-agent-deep-reinforcement-learning-in-15-lines-of-code-using-pettingzoo-e0b963c0820b">https://towardsdatascience.com/multi-agent-deep-reinforcement-learning-in-15-lines-of-code-using-pettingzoo-e0b963c0820b</a></p>
</aside>
<aside class="footnote brackets" id="details-ppo" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id10">5</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/">https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/</a></p>
</aside>
<aside class="footnote brackets" id="understand-lstm" role="note">
<span class="label"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id12">1</a>,<a role="doc-backlink" href="#id13">2</a>)</span>
<p><a class="reference external" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="game-implementation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Werewolf - The Implementation</p>
      </div>
    </a>
    <a class="right-next"
       href="agent-implementation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Agent Implementation</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pomdps">POMDPs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rl-marl">RL &amp; MARL</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ppo">PPO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lstms">LSTMs</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By George Savin
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>