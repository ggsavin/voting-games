{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from voting_games.werewolf_env_v0 import plurality_env, pare, Phase, Roles\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from notebooks.learning_agents.models import ActorCriticAgent\n",
    "from notebooks.learning_agents.utils import play_recurrent_game\n",
    "from notebooks.learning_agents.static_agents import random_approval_wolf, random_plurality_wolf\n",
    "import notebooks.learning_agents.stats as indicators \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(gameplay-indicators-list)=\n",
    "# Gameplay Indicators\n",
    "\n",
    "Indicators gauge certain trends and facts, and can indicate the level of something such as learned behavior or skill. Basic indicators such as win-rates, total/average score and neural network loss are almost ubiquitous to RL papers due to their simplicity and interpretability. A reader knows immediately how the agent is doing just by looking at them. In Werewolf, we consider win-rate as our most basic indicator. \n",
    "\n",
    "To better undestand our learned agents behavior, we want more in-depth and descriptive indicators, that may or may not generalize well to other problems. We can categorize these as:\n",
    "- Win-rate adjacent : time-to-win and time between wolf executions \n",
    "- Tie Indicators : when and what did agents do when tie's occured\n",
    "- Targetting Indicators: Novel heuristics we designed to try and identify the reasoning behind how agents target others via their votes.\n",
    "\n",
    "\n",
    "Each indicator has a code snippet associated with it, so anyone extending or replicating this project can use them as examples.\n",
    "\n",
    "```{note}\n",
    "The way the environment stores history is slightly different than observations. Whereas the latter stores the prior votes, env.history steps have the votes and the outcomes that occured at that particular day/phase/round.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load up data\n",
    "\n",
    "We are going to use replays from our trained agents to investigate these various markers. 1000 games of each voting type will be used.\n",
    "\n",
    "### Plurality Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained villagers won 486 games\n",
      "Untrained villagers won 47 games\n"
     ]
    }
   ],
   "source": [
    "env = plurality_env(num_agents=10, werewolves=2, num_accusations=2)\n",
    "observations, _, _, _, _ = env.reset()\n",
    "\n",
    "obs_size= env.convert_obs(observations['player_0']['observation']).shape[-1]\n",
    "\n",
    "untrained_plurality_agent = ActorCriticAgent({\"rec_hidden_size\": 128, \n",
    "                                        \"rec_layers\": 1,\n",
    "                                        \"joint_mlp_size\": 128,\n",
    "                                        \"split_mlp_size\": 128,\n",
    "                                        \"num_votes\": 1,\n",
    "                                        \"approval_states\": 10},\n",
    "                                        num_players=10,\n",
    "                                        obs_size=obs_size)\n",
    "\n",
    "trained_plurality_agent = ActorCriticAgent({\"rec_hidden_size\": 128,\n",
    "                                        \"rec_layers\": 1, \n",
    "                                        \"joint_mlp_size\": 128,\n",
    "                                        \"split_mlp_size\": 128,\n",
    "                                        \"num_votes\": 1,\n",
    "                                        \"approval_states\": 10},\n",
    "                                        num_players=10,\n",
    "                                        obs_size=obs_size)\n",
    "trained_plurality_agent.load_state_dict(torch.load(\"stored_agents/lstm_first_no_one_hot_128_128/plurality_agent_10_score_46\"))\n",
    "\n",
    "# random_agent = None\n",
    "\n",
    "trained_plurality_wins, trained_plurality_replays = play_recurrent_game(env, random_plurality_wolf, trained_plurality_agent, num_times=1000, hidden_state_size=128, voting_type=\"plurality\")\n",
    "untrained_plurality_wins, untrained_plurality_replays = play_recurrent_game(env, random_plurality_wolf, untrained_plurality_agent, num_times=1000, hidden_state_size=128, voting_type=\"plurality\")\n",
    "# random_wins, random_replays = play_recurrent_game_w_replays(env, random_coordinated_single_wolf, random_agent, num_times=1000, hidden_state_size=128, voting_type=\"plurality\")\n",
    "\n",
    "trained_plurality_villager_wins = [r for r in trained_plurality_replays if r[-1][\"winners\"] == Roles.VILLAGER]\n",
    "print(f'Trained villagers won {trained_plurality_wins} games')\n",
    "untrained_plurality_villager_wins = [r for r in untrained_plurality_replays if r[-1][\"winners\"] == Roles.VILLAGER]\n",
    "print(f'Untrained villagers won {untrained_plurality_wins} games')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approval Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained villagers won 507 games\n",
      "Untrained villagers won 62 games\n"
     ]
    }
   ],
   "source": [
    "env = pare(num_agents=10, werewolves=2, num_accusations=2)\n",
    "observations, _, _, _, _ = env.reset()\n",
    "\n",
    "obs_size= env.convert_obs(observations['player_0']['observation']).shape[-1]\n",
    "observations['player_0']['observation']\n",
    "\n",
    "untrained_approval_agent = ActorCriticAgent({\"rec_hidden_size\": 256, \n",
    "                                        \"rec_layers\": 1,\n",
    "                                        \"joint_mlp_size\": 128,\n",
    "                                        \"split_mlp_size\": 128,\n",
    "                                        \"num_votes\": 10,\n",
    "                                        \"approval_states\": 3},\n",
    "                                        num_players=10,\n",
    "                                        obs_size=obs_size)\n",
    "\n",
    "trained_approval_agent = ActorCriticAgent({\"rec_hidden_size\": 256,\n",
    "                                        \"rec_layers\": 1, \n",
    "                                        \"joint_mlp_size\": 128,\n",
    "                                        \"split_mlp_size\": 128,\n",
    "                                        \"num_votes\": 10,\n",
    "                                        \"approval_states\": 3},\n",
    "                                        num_players=10,\n",
    "                                        obs_size=obs_size)\n",
    "trained_approval_agent.load_state_dict(torch.load(\"stored_agents/lstm_first_no_one_hot_256_128/approval_agent_10_score_49\"))\n",
    "\n",
    "# random_agent = None\n",
    "\n",
    "trained_approval_wins, trained_approval_replays = play_recurrent_game(env, random_approval_wolf, trained_approval_agent, num_times=1000, hidden_state_size=256, voting_type=\"approval\")\n",
    "untrained_approval_wins, untrained_approval_replays = play_recurrent_game(env, random_approval_wolf, untrained_approval_agent, num_times=1000, hidden_state_size=256, voting_type=\"approval\")\n",
    "# random_wins, random_replays = play_recurrent_game_w_replays(env, random_coordinated_single_wolf, random_agent, num_times=1000, hidden_state_size=128, voting_type=\"plurality\")\n",
    "\n",
    "trained_approval_villager_wins = [r for r in trained_approval_replays if r[-1][\"winners\"] == Roles.VILLAGER]\n",
    "print(f'Trained villagers won {trained_approval_wins} games')\n",
    "untrained_approval_villager_wins = [r for r in untrained_approval_replays if r[-1][\"winners\"] == Roles.VILLAGER]\n",
    "print(f'Untrained villagers won {untrained_approval_wins} games')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days elapsed before a villager win\n",
    "\n",
    "Looking at the average amount of days elapsed before villagers win is a metric that highlights positive learning and collaboration trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average amount of days until a win is achieved by villagers in plurality games\n",
      "\t Trained villagers : 2.987368\n",
      "\t Untrained villagers : 3.076923\n",
      "\n",
      "\n",
      "Average amount of days until a win is achieved by villagers in approval games\n",
      "\t Trained villagers : 2.970833\n",
      "\t Untrained villagers : 3.376471\n"
     ]
    }
   ],
   "source": [
    "print(\"Average amount of days until a win is achieved by villagers in plurality games\")\n",
    "print(f'\\t Trained villagers : {np.mean([villager_win[-1][\"day\"] for villager_win in trained_plurality_villager_wins]):2f}')\n",
    "print(f'\\t Untrained villagers : {np.mean([villager_win[-1][\"day\"] for villager_win in untrained_plurality_villager_wins]):2f}')\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average amount of days until a win is achieved by villagers in approval games\")\n",
    "print(f'\\t Trained villagers : {np.mean([villager_win[-1][\"day\"] for villager_win in trained_approval_villager_wins]):2f}')\n",
    "print(f'\\t Untrained villagers : {np.mean([villager_win[-1][\"day\"] for villager_win in untrained_approval_villager_wins]):2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days between wolf executions\n",
    "\n",
    "Looking at the distance in days between wolf executions also highlights positive trends in learning and collaboration, as the lower the number, the more likely villagers were able to confidently coordinate and identify the wolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average amount of days until the next wolf was killed in plurality games for 2 wolf environments\n",
      "\tDays between wolf kills for trained agents : 1.581\n",
      "\tDays between wolf kills for untrained agents : 1.667\n",
      "\n",
      "\n",
      "Average amount of days until the next wolf was killed in approval games for 2 wolf environments\n",
      "\tDays between wolf kills for trained agents : 1.448\n",
      "\tDays between wolf kills for untrained agents : 1.659\n"
     ]
    }
   ],
   "source": [
    "print(\"Average amount of days until the next wolf was killed in plurality games for 2 wolf environments\")\n",
    "wolf_execution_days = \\\n",
    "    [indicators._when_did_wolves_get_killed(trained_villager_win) for trained_villager_win in trained_plurality_villager_wins]\n",
    "wolf_execution_duration_between = [b-a for a,b in wolf_execution_days]\n",
    "print(f'\\tDays between wolf kills for trained agents : {np.mean(wolf_execution_duration_between):.3f}')\n",
    "\n",
    "wolf_execution_days = \\\n",
    "    [indicators._when_did_wolves_get_killed(untrained_villager_win) for untrained_villager_win in untrained_plurality_villager_wins]\n",
    "wolf_execution_duration_between = [b-a for a,b in wolf_execution_days]\n",
    "print(f'\\tDays between wolf kills for untrained agents : {np.mean(wolf_execution_duration_between):.3f}')\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average amount of days until the next wolf was killed in approval games for 2 wolf environments\")\n",
    "wolf_execution_days = \\\n",
    "    [indicators._when_did_wolves_get_killed(trained_villager_win) for trained_villager_win in trained_approval_villager_wins]\n",
    "wolf_execution_duration_between = [b-a for a,b in wolf_execution_days]\n",
    "print(f'\\tDays between wolf kills for trained agents : {np.mean(wolf_execution_duration_between):.3f}')\n",
    "\n",
    "wolf_execution_days = \\\n",
    "    [indicators._when_did_wolves_get_killed(untrained_villager_win) for untrained_villager_win in untrained_approval_villager_wins]\n",
    "wolf_execution_duration_between = [b-a for a,b in wolf_execution_days]\n",
    "print(f'\\tDays between wolf kills for untrained agents : {np.mean(wolf_execution_duration_between):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targetting Indicators\n",
    "\n",
    "Picking the right indicators to try and describe targetting behavior is not straightforward, and differs between plurality and approval voting. Below are the ones currently chosen for both game types, along with a rendering of them across days and phases in a randomly selected game.\n",
    "\n",
    "For further analysis, we also use `indicators._game_avg_records(replays,indicator_function)` to average these values across phases and days for every replay.\n",
    "\n",
    "#### Plurality\n",
    "\n",
    "To try an make sense of targetting, we chose to look at:\n",
    "- **Ratio of unique villager targets**: How many unique players are targetted on average by villagers?\n",
    "- **Ratio of villagers voting for themselves**: How much self targetting is occuring on average by villagers? \n",
    "- **Percentage of villagers targetting dead players**: How many villagers are voting for dead players out of total votes cast?\n",
    "- **Percentage of villager votes targetting wolves and dead wolves**: How many villagers are voting for werewolves out of total votes cast?\n",
    "\n",
    "These should be good enough to indicate cooperation as well as general role comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wolves : ['player_0', 'player_3']\n",
      "\n",
      "Day : 1 | Phase : 0 | Round : 0\n",
      "Villager votes : [9, 9, 9, 3, 9, 9, 5, 2]\n",
      "\t | - Ratio of unique players targetted : 0.5\n",
      "\t | - 0.125 of the votes targetting wolves\n",
      "\t | - 0.125 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 1 | Phase : 0 | Round : 1\n",
      "Villager votes : [3, 9, 9, 7, 7, 8, 6, 7]\n",
      "\t | - Ratio of unique players targetted : 0.625\n",
      "\t | - 0.125 of the votes targetting wolves\n",
      "\t | - 0.125 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 1 | Phase : 1 | Round : 0\n",
      "Villager votes : [2, 8, 9, 8, 9, 0, 3, 8]\n",
      "\t | - Ratio of unique players targetted : 0.625\n",
      "\t | - 0.250 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 2 | Phase : 0 | Round : 0\n",
      "Villager votes : [9, 6, 9, 8, 3, 8]\n",
      "\t | - Ratio of unique players targetted : 0.6666666666666666\n",
      "\t | - 0.167 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.333 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 2 | Phase : 0 | Round : 1\n",
      "Villager votes : [8, 3, 3, 8, 3, 8]\n",
      "\t | - Ratio of unique players targetted : 0.3333333333333333\n",
      "\t | - 0.500 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 2 | Phase : 1 | Round : 0\n",
      "Villager votes : [7, 3, 0, 0, 0, 0]\n",
      "\t | - Ratio of unique players targetted : 0.5\n",
      "\t | - 0.833 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 3 | Phase : 0 | Round : 0\n",
      "Villager votes : [3, 8, 8, 0, 9]\n",
      "\t | - Ratio of unique players targetted : 0.8\n",
      "\t | - 0.400 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.400 share of villager votes targetting dead players\n",
      "\t | - 0.200 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 3 | Phase : 0 | Round : 1\n",
      "Villager votes : [8, 7, 3, 3, 8]\n",
      "\t | - Ratio of unique players targetted : 0.6\n",
      "\t | - 0.400 of the votes targetting wolves\n",
      "\t | - 0.0 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n",
      "Day : 3 | Phase : 1 | Round : 0\n",
      "Villager votes : [3, 3, 6, 3, 6]\n",
      "\t | - Ratio of unique players targetted : 0.4\n",
      "\t | - 0.600 of the votes targetting wolves\n",
      "\t | - 0.2 of villagers targetting themselves\n",
      "\t | - 0.000 share of villager votes targetting dead players\n",
      "\t | - 0.000 share of villager votes targetting dead wolves\n",
      "\n"
     ]
    }
   ],
   "source": [
    "record = indicators._plurality_target_indicators(trained_plurality_villager_wins[0], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approval\n",
    "\n",
    "Because of the extra dimensions and expressability of approval voting, trying to determine behavior for these agents is much harder. We thus collect many different and interelated indicators to see what combinations of them might give us the most insight. Some may seem redudant, but providing different perspectives to certain indicators will hopefully paint a more complete picture while we analyze our data.\n",
    "\n",
    "The ones we are currently looking at are:\n",
    "- **average target count**: How many candidates does a single agent dissaprove of on average?\n",
    "- **average like count**: How many candidates does a single agent like on average?\n",
    "- **average neutral count**: How many candidates does a single agent use a neutral option for on average?\n",
    "- **average self target**: How likely is it a single agent will target/dissaprove of themselves?\n",
    "- **average self like**: How likely is it that a single agent will like themselves?\n",
    "- **percentage of wolves in top targets**: How many targets are allocated towards werewolves when considering a top percentage of targets cast. \n",
    "- **percentage of wolves in top likes**: How many likes are allocated towards werewolves when considering a top percentage of likes cast.\n",
    "- **percent of votes targetting dead players**: How many targets are towards dead players out of all targets cast.\n",
    "- **percent of votes targetting dead wolves**: How many targets are towards dead werewolves out of all targets cast.\n",
    "- **percent of votes targetting wolves that are still alive**: How many targets are towards werewolves still in the game out of all targets cast. \n",
    "- **percent of likes for dead wolves**: How many likes are towards dead werewolves out of all likes cast.\n",
    "- **percent of likes for wolves that are still alive**: How many likes are towards werewolves still in the game out of all likes cast.\n",
    "- **percent of likes towards dead villagers**: How many likes are towards dead villagers out of all likes cast.\n",
    "- **percent of likes towards villagers that are still alive**: How many likes are towards villagers still in the game out of all likes cast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day : 1 | Phase : 0 - Accusation Phase | Round : 0\n",
      "\t | - avg targetted 3.75, liked 3.00, neutral 3.25\n",
      "\t | - 0.50 share of villagers targeted themselves, and 0.38 liked themselves\n",
      "\t | - 0.0 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.00\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.20)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.17)\n",
      "\t | - % of likes towards dead villagers (0.00), and towards living villagers (0.83)\n",
      "\n",
      "\n",
      "Day : 1 | Phase : 0 - Accusation Phase | Round : 1\n",
      "\t | - avg targetted 2.62, liked 3.38, neutral 4.00\n",
      "\t | - 0.12 share of villagers targeted themselves, and 0.38 liked themselves\n",
      "\t | - 0.3333333333333333 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.00\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.24)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.19)\n",
      "\t | - % of likes towards dead villagers (0.00), and towards living villagers (0.81)\n",
      "\n",
      "\n",
      "Day : 1 | Phase : 1 - Voting Phase | Round : 0\n",
      "\t | - avg targetted 3.25, liked 3.25, neutral 3.50\n",
      "\t | - 0.25 share of villagers targeted themselves, and 0.25 liked themselves\n",
      "\t | - 0.0 wolves targetted in top votes\n",
      "\t | - 0.5 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.00\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.12)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.31)\n",
      "\t | - % of likes towards dead villagers (0.00), and towards living villagers (0.69)\n",
      "\n",
      "\n",
      "Day : 2 | Phase : 0 - Accusation Phase | Round : 0\n",
      "\t | - avg targetted 3.33, liked 3.83, neutral 2.83\n",
      "\t | - 0.33 share of villagers targeted themselves, and 0.50 liked themselves\n",
      "\t | - 0.5 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.25\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.20)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.17)\n",
      "\t | - % of likes towards dead villagers (0.17), and towards living villagers (0.65)\n",
      "\n",
      "\n",
      "Day : 2 | Phase : 0 - Accusation Phase | Round : 1\n",
      "\t | - avg targetted 3.00, liked 4.00, neutral 3.00\n",
      "\t | - 0.33 share of villagers targeted themselves, and 0.50 liked themselves\n",
      "\t | - 0.5 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.22\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.22)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.21)\n",
      "\t | - % of likes towards dead villagers (0.17), and towards living villagers (0.62)\n",
      "\n",
      "\n",
      "Day : 2 | Phase : 1 - Voting Phase | Round : 0\n",
      "\t | - avg targetted 3.17, liked 3.17, neutral 3.67\n",
      "\t | - 0.17 share of villagers targeted themselves, and 0.33 liked themselves\n",
      "\t | - 0.5 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.32\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.37)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.11)\n",
      "\t | - % of likes towards dead villagers (0.16), and towards living villagers (0.74)\n",
      "\n",
      "\n",
      "Day : 3 | Phase : 0 - Accusation Phase | Round : 0\n",
      "\t | - avg targetted 4.25, liked 3.25, neutral 2.50\n",
      "\t | - 0.00 share of villagers targeted themselves, and 0.75 liked themselves\n",
      "\t | - 0.0 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.65\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.18)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.15)\n",
      "\t | - % of likes towards dead villagers (0.08), and towards living villagers (0.77)\n",
      "\n",
      "\n",
      "Day : 3 | Phase : 0 - Accusation Phase | Round : 1\n",
      "\t | - avg targetted 2.50, liked 3.25, neutral 4.25\n",
      "\t | - 0.00 share of villagers targeted themselves, and 0.50 liked themselves\n",
      "\t | - 1.0 wolves targetted in top votes\n",
      "\t | - 0.5 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.30\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.50)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.23)\n",
      "\t | - % of likes towards dead villagers (0.31), and towards living villagers (0.46)\n",
      "\n",
      "\n",
      "Day : 3 | Phase : 1 - Voting Phase | Round : 0\n",
      "\t | - avg targetted 3.25, liked 2.25, neutral 4.50\n",
      "\t | - 0.00 share of villagers targeted themselves, and 0.00 liked themselves\n",
      "\t | - 1.0 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.38\n",
      "\t | - % of votes for dead wolves (0.00), and towards living wolves (0.46)\n",
      "\t | - % of likes towards dead wolves (0.00) and towards living wolves (0.11)\n",
      "\t | - % of likes towards dead villagers (0.56), and towards living villagers (0.33)\n",
      "\n",
      "\n",
      "Day : 4 | Phase : 0 - Accusation Phase | Round : 0\n",
      "\t | - avg targetted 3.33, liked 3.67, neutral 3.00\n",
      "\t | - 0.33 share of villagers targeted themselves, and 0.67 liked themselves\n",
      "\t | - 0.0 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.50\n",
      "\t | - % of votes for dead wolves (0.10), and towards living wolves (0.20)\n",
      "\t | - % of likes towards dead wolves (0.18) and towards living wolves (0.09)\n",
      "\t | - % of likes towards dead villagers (0.36), and towards living villagers (0.36)\n",
      "\n",
      "\n",
      "Day : 4 | Phase : 0 - Accusation Phase | Round : 1\n",
      "\t | - avg targetted 4.00, liked 2.00, neutral 4.00\n",
      "\t | - 0.00 share of villagers targeted themselves, and 0.00 liked themselves\n",
      "\t | - 0.0 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.75\n",
      "\t | - % of votes for dead wolves (0.17), and towards living wolves (0.17)\n",
      "\t | - % of likes towards dead wolves (0.17) and towards living wolves (0.17)\n",
      "\t | - % of likes towards dead villagers (0.33), and towards living villagers (0.33)\n",
      "\n",
      "\n",
      "Day : 4 | Phase : 1 - Voting Phase | Round : 0\n",
      "\t | - avg targetted 3.00, liked 4.33, neutral 2.67\n",
      "\t | - 0.33 share of villagers targeted themselves, and 0.33 liked themselves\n",
      "\t | - 0.5 wolves targetted in top votes\n",
      "\t | - 0.0 wolves liked in top likes\n",
      "\t | - % of votes towards dead players (0.56\n",
      "\t | - % of votes for dead wolves (0.11), and towards living wolves (0.22)\n",
      "\t | - % of likes towards dead wolves (0.08) and towards living wolves (0.08)\n",
      "\t | - % of likes towards dead villagers (0.46), and towards living villagers (0.38)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = indicators._approval_target_indicators(trained_approval_villager_wins[0], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ties\n",
    "\n",
    "Ties are quite common, and could possibly be used strategically. Knowning when/if ties are occuring could possibly lead to a better understanding of agent voting patterns.\n",
    "\n",
    "What we are currenly looking for is:\n",
    "- What percentage of voting rounds are ties?\n",
    "- How often do ties in accusation rounds lead to ties in voting rounds?\n",
    "- If a wolf gets lucky and survives a tied voting round, how likey is it they get executed the next voting round?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two functions we use to achieve this:\n",
    "- `indicators._game_tie_info(game_replay, voting_type=None)` which returns if there was a tie, if and which wolf was targetted, and if a wolf died during the phase. This is done for every day and every phase in a game\n",
    "- `indicators._process_tie_info(tie_records)` takes the results above and returns:\n",
    "    - percentage of ties in accusation phases per game\n",
    "    - percentage of ties in voting phases per game\n",
    "    - likelihood of a tie in a voting phase given a tie in the prior accusation phases\n",
    "    - likelihood of a wolf getting targetting in a subsequent voting round after getting lucky and surviving a tie round where they were a target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plurality tie indicators\n",
      "\tLikelihood of ties in accusation phases : 0.29\n",
      "\tLikelihood of ties in voting phases : 0.19\n",
      "\tLikelihood of a tie in a voting phase given a tie in the prior accusation phases 0.21\n",
      "\tLikelihood of a wolf getting targetting in a subsequent voting round if they survived a tie : 0.77\n",
      "\n",
      "\n",
      "Approval tie indicators\n",
      "\tLikelihood of ties in accusation phases : 0.36\n",
      "\tLikelihood of ties in voting phases : 0.31\n",
      "\tLikelihood of a tie in a voting phase given a tie in the prior accusation phases 0.32\n",
      "\tLikelihood of a wolf getting targetting in a subsequent voting round if they survived a tie : 0.63\n"
     ]
    }
   ],
   "source": [
    "tgps = \\\n",
    "    np.nanmean(np.stack([indicators._process_tie_info(indicators._game_tie_info(trained_villager_win, voting_type=\"plurality\")) for trained_villager_win in trained_plurality_villager_wins]),axis= 0)\n",
    "tgas = \\\n",
    "    np.nanmean(np.stack([indicators._process_tie_info(indicators._game_tie_info(trained_villager_win, voting_type=\"approval\")) for trained_villager_win in trained_approval_villager_wins]), axis=0)\n",
    "\n",
    "print(\"Plurality tie indicators\")\n",
    "print(f'\\tLikelihood of ties in accusation phases : {tgps[0]:.2f}')\n",
    "print(f'\\tLikelihood of ties in voting phases : {tgps[1]:.2f}')\n",
    "print(f'\\tLikelihood of a tie in a voting phase given a tie in the prior accusation phases {tgps[2]:.2f}')\n",
    "print(f'\\tLikelihood of a wolf getting targetting in a subsequent voting round if they survived a tie : {tgps[3]:.2f}')\n",
    "print(\"\\n\")\n",
    "print(\"Approval tie indicators\")\n",
    "print(f'\\tLikelihood of ties in accusation phases : {tgas[0]:.2f}')\n",
    "print(f'\\tLikelihood of ties in voting phases : {tgas[1]:.2f}')\n",
    "print(f'\\tLikelihood of a tie in a voting phase given a tie in the prior accusation phases {tgas[2]:.2f}')\n",
    "print(f'\\tLikelihood of a wolf getting targetting in a subsequent voting round if they survived a tie : {tgas[3]:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}